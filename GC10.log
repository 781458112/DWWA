2022-06-20 14:51:33,974 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1: GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.4.r11.4/compiler.30033411_0
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.8.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.0
OpenCV: 4.5.5
MMCV: 1.3.16
MMCV Compiler: GCC 7.5
MMCV CUDA Compiler: 11.4
MMDetection: 2.18.0+
------------------------------------------------------------

2022-06-20 14:51:34,395 - mmdet - INFO - Distributed training: False
2022-06-20 14:51:34,778 - mmdet - INFO - Config:
model = dict(
    type='FasterRCNN',
    backbone=dict(
        type='xiaobo_DetectoRS_ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50'),
        dcn=dict(type='DCN', deform_groups=1),
        stage_with_dcn=(False, True, True, True),
        output_img=True),
    neck=dict(
        type='RFP',
        in_channels=[256, 512, 1024, 2048, 4096],
        out_channels=256,
        num_outs=5,
        rfp_steps=2,
        aspp_out_channels=64,
        aspp_dilations=(1, 3, 6, 1),
        rfp_backbone=dict(
            rfp_inplanes=256,
            type='xiaobo_DetectoRS_ResNet',
            depth=50,
            num_stages=4,
            out_indices=(0, 1, 2, 3),
            frozen_stages=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            norm_eval=True,
            pretrained='torchvision://resnet50',
            style='pytorch')),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=10,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(
                type='SmoothL1Loss', beta=0.1111111111111111,
                loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1333, 888), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 888),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_train2017.json',
        img_prefix='data/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 888), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 888),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 888),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox')
optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=2000,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=14)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/home/zh/zhao/mmdetection-2.18.0-new/voc_pretrained_resnet50_faster_weights_new_classes_7.pth'
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/cascade_rcnn_r50_rfp_1x_coco'
gpu_ids = range(0, 1)

2022-06-20 14:51:40,746 - mmdet - INFO - Use load_from_torchvision loader
2022-06-20 14:51:40,997 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

missing keys in source state_dict: xfm.h0_col, xfm.h1_col, xfm.h0_row, xfm.h1_row, conv2.weight, layer5.se1.fc.0.weight, layer5.se1.fc.3.weight, layer5.se2.fc.0.weight, layer5.se2.fc.3.weight, layer5.cv1.weight, layer5.cv1.conv_offset.weight, layer5.cv1.conv_offset.bias, layer5.cv2.weight, layer5.cv2.conv_offset.weight, layer5.cv2.conv_offset.bias, layer5.cv3.weight, layer5.cv3.conv_offset.weight, layer5.cv3.conv_offset.bias, layer5.cv5.weight, layer5.cv5.conv_offset.weight, layer5.cv5.conv_offset.bias, layer5.cv6.weight, layer5.cv6.conv_offset.weight, layer5.cv6.conv_offset.bias, layer5.switch.weight, layer5.switch.bias, layer5.xfm.h0_col, layer5.xfm.h1_col, layer5.xfm.h0_row, layer5.xfm.h1_row, layer1.0.cv3.weight, layer1.0.xfm.h0_col, layer1.0.xfm.h1_col, layer1.0.xfm.h0_row, layer1.0.xfm.h1_row, layer1.1.cv3.weight, layer1.1.xfm.h0_col, layer1.1.xfm.h1_col, layer1.1.xfm.h0_row, layer1.1.xfm.h1_row, layer1.2.cv3.weight, layer1.2.xfm.h0_col, layer1.2.xfm.h1_col, layer1.2.xfm.h0_row, layer1.2.xfm.h1_row, layer2.0.xfm.h0_col, layer2.0.xfm.h1_col, layer2.0.xfm.h0_row, layer2.0.xfm.h1_row, layer2.0.cv3.weight, layer2.0.cv3.conv_offset.weight, layer2.0.cv3.conv_offset.bias, layer2.1.conv2.conv_offset.weight, layer2.1.conv2.conv_offset.bias, layer2.1.cv3.weight, layer2.1.cv3.conv_offset.weight, layer2.1.cv3.conv_offset.bias, layer2.1.xfm.h0_col, layer2.1.xfm.h1_col, layer2.1.xfm.h0_row, layer2.1.xfm.h1_row, layer2.2.conv2.conv_offset.weight, layer2.2.conv2.conv_offset.bias, layer2.2.cv3.weight, layer2.2.cv3.conv_offset.weight, layer2.2.cv3.conv_offset.bias, layer2.2.xfm.h0_col, layer2.2.xfm.h1_col, layer2.2.xfm.h0_row, layer2.2.xfm.h1_row, layer2.3.conv2.conv_offset.weight, layer2.3.conv2.conv_offset.bias, layer2.3.cv3.weight, layer2.3.cv3.conv_offset.weight, layer2.3.cv3.conv_offset.bias, layer2.3.xfm.h0_col, layer2.3.xfm.h1_col, layer2.3.xfm.h0_row, layer2.3.xfm.h1_row, layer3.0.xfm.h0_col, layer3.0.xfm.h1_col, layer3.0.xfm.h0_row, layer3.0.xfm.h1_row, layer3.0.cv3.weight, layer3.0.cv3.conv_offset.weight, layer3.0.cv3.conv_offset.bias, layer3.1.conv2.conv_offset.weight, layer3.1.conv2.conv_offset.bias, layer3.1.cv3.weight, layer3.1.cv3.conv_offset.weight, layer3.1.cv3.conv_offset.bias, layer3.1.xfm.h0_col, layer3.1.xfm.h1_col, layer3.1.xfm.h0_row, layer3.1.xfm.h1_row, layer3.2.conv2.conv_offset.weight, layer3.2.conv2.conv_offset.bias, layer3.2.cv3.weight, layer3.2.cv3.conv_offset.weight, layer3.2.cv3.conv_offset.bias, layer3.2.xfm.h0_col, layer3.2.xfm.h1_col, layer3.2.xfm.h0_row, layer3.2.xfm.h1_row, layer3.3.conv2.conv_offset.weight, layer3.3.conv2.conv_offset.bias, layer3.3.cv3.weight, layer3.3.cv3.conv_offset.weight, layer3.3.cv3.conv_offset.bias, layer3.3.xfm.h0_col, layer3.3.xfm.h1_col, layer3.3.xfm.h0_row, layer3.3.xfm.h1_row, layer3.4.conv2.conv_offset.weight, layer3.4.conv2.conv_offset.bias, layer3.4.cv3.weight, layer3.4.cv3.conv_offset.weight, layer3.4.cv3.conv_offset.bias, layer3.4.xfm.h0_col, layer3.4.xfm.h1_col, layer3.4.xfm.h0_row, layer3.4.xfm.h1_row, layer3.5.conv2.conv_offset.weight, layer3.5.conv2.conv_offset.bias, layer3.5.cv3.weight, layer3.5.cv3.conv_offset.weight, layer3.5.cv3.conv_offset.bias, layer3.5.xfm.h0_col, layer3.5.xfm.h1_col, layer3.5.xfm.h0_row, layer3.5.xfm.h1_row, layer4.0.xfm.h0_col, layer4.0.xfm.h1_col, layer4.0.xfm.h0_row, layer4.0.xfm.h1_row, layer4.0.cv3.weight, layer4.0.cv3.conv_offset.weight, layer4.0.cv3.conv_offset.bias, layer4.1.conv2.conv_offset.weight, layer4.1.conv2.conv_offset.bias, layer4.1.cv3.weight, layer4.1.cv3.conv_offset.weight, layer4.1.cv3.conv_offset.bias, layer4.1.xfm.h0_col, layer4.1.xfm.h1_col, layer4.1.xfm.h0_row, layer4.1.xfm.h1_row, layer4.2.conv2.conv_offset.weight, layer4.2.conv2.conv_offset.bias, layer4.2.cv3.weight, layer4.2.cv3.conv_offset.weight, layer4.2.cv3.conv_offset.bias, layer4.2.xfm.h0_col, layer4.2.xfm.h1_col, layer4.2.xfm.h0_row, layer4.2.xfm.h1_row, softmaxattention1.se1.fc.0.weight, softmaxattention1.se1.fc.3.weight, softmaxattention1.se2.fc.0.weight, softmaxattention1.se2.fc.3.weight, softmaxattention1.cv1.weight, softmaxattention1.cv1.conv_offset.weight, softmaxattention1.cv1.conv_offset.bias, softmaxattention1.cv2.weight, softmaxattention1.cv2.conv_offset.weight, softmaxattention1.cv2.conv_offset.bias, softmaxattention1.cv3.weight, softmaxattention1.cv3.conv_offset.weight, softmaxattention1.cv3.conv_offset.bias, softmaxattention1.cv5.weight, softmaxattention1.cv5.conv_offset.weight, softmaxattention1.cv5.conv_offset.bias, softmaxattention1.cv6.weight, softmaxattention1.cv6.conv_offset.weight, softmaxattention1.cv6.conv_offset.bias, softmaxattention1.switch.weight, softmaxattention1.switch.bias, softmaxattention1.xfm.h0_col, softmaxattention1.xfm.h1_col, softmaxattention1.xfm.h0_row, softmaxattention1.xfm.h1_row, softmaxattention1.cv7.weight

2022-06-20 14:51:41,277 - mmdet - INFO - Use load_from_torchvision loader
2022-06-20 14:51:41,503 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

missing keys in source state_dict: xfm.h0_col, xfm.h1_col, xfm.h0_row, xfm.h1_row, conv2.weight, layer5.se1.fc.0.weight, layer5.se1.fc.3.weight, layer5.se2.fc.0.weight, layer5.se2.fc.3.weight, layer5.cv1.weight, layer5.cv2.weight, layer5.cv3.weight, layer5.cv5.weight, layer5.cv6.weight, layer5.switch.weight, layer5.switch.bias, layer5.xfm.h0_col, layer5.xfm.h1_col, layer5.xfm.h0_row, layer5.xfm.h1_row, layer1.0.cv3.weight, layer1.0.xfm.h0_col, layer1.0.xfm.h1_col, layer1.0.xfm.h0_row, layer1.0.xfm.h1_row, layer1.1.cv3.weight, layer1.1.xfm.h0_col, layer1.1.xfm.h1_col, layer1.1.xfm.h0_row, layer1.1.xfm.h1_row, layer1.2.cv3.weight, layer1.2.xfm.h0_col, layer1.2.xfm.h1_col, layer1.2.xfm.h0_row, layer1.2.xfm.h1_row, layer2.0.xfm.h0_col, layer2.0.xfm.h1_col, layer2.0.xfm.h0_row, layer2.0.xfm.h1_row, layer2.0.cv3.weight, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.cv3.weight, layer2.1.xfm.h0_col, layer2.1.xfm.h1_col, layer2.1.xfm.h0_row, layer2.1.xfm.h1_row, layer2.2.cv3.weight, layer2.2.xfm.h0_col, layer2.2.xfm.h1_col, layer2.2.xfm.h0_row, layer2.2.xfm.h1_row, layer2.3.cv3.weight, layer2.3.xfm.h0_col, layer2.3.xfm.h1_col, layer2.3.xfm.h0_row, layer2.3.xfm.h1_row, layer3.0.xfm.h0_col, layer3.0.xfm.h1_col, layer3.0.xfm.h0_row, layer3.0.xfm.h1_row, layer3.0.cv3.weight, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.cv3.weight, layer3.1.xfm.h0_col, layer3.1.xfm.h1_col, layer3.1.xfm.h0_row, layer3.1.xfm.h1_row, layer3.2.cv3.weight, layer3.2.xfm.h0_col, layer3.2.xfm.h1_col, layer3.2.xfm.h0_row, layer3.2.xfm.h1_row, layer3.3.cv3.weight, layer3.3.xfm.h0_col, layer3.3.xfm.h1_col, layer3.3.xfm.h0_row, layer3.3.xfm.h1_row, layer3.4.cv3.weight, layer3.4.xfm.h0_col, layer3.4.xfm.h1_col, layer3.4.xfm.h0_row, layer3.4.xfm.h1_row, layer3.5.cv3.weight, layer3.5.xfm.h0_col, layer3.5.xfm.h1_col, layer3.5.xfm.h0_row, layer3.5.xfm.h1_row, layer4.0.xfm.h0_col, layer4.0.xfm.h1_col, layer4.0.xfm.h0_row, layer4.0.xfm.h1_row, layer4.0.cv3.weight, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.cv3.weight, layer4.1.xfm.h0_col, layer4.1.xfm.h1_col, layer4.1.xfm.h0_row, layer4.1.xfm.h1_row, layer4.2.cv3.weight, layer4.2.xfm.h0_col, layer4.2.xfm.h1_col, layer4.2.xfm.h0_row, layer4.2.xfm.h1_row, softmaxattention1.se1.fc.0.weight, softmaxattention1.se1.fc.3.weight, softmaxattention1.se2.fc.0.weight, softmaxattention1.se2.fc.3.weight, softmaxattention1.cv1.weight, softmaxattention1.cv1.conv_offset.weight, softmaxattention1.cv1.conv_offset.bias, softmaxattention1.cv2.weight, softmaxattention1.cv2.conv_offset.weight, softmaxattention1.cv2.conv_offset.bias, softmaxattention1.cv3.weight, softmaxattention1.cv3.conv_offset.weight, softmaxattention1.cv3.conv_offset.bias, softmaxattention1.cv5.weight, softmaxattention1.cv5.conv_offset.weight, softmaxattention1.cv5.conv_offset.bias, softmaxattention1.cv6.weight, softmaxattention1.cv6.conv_offset.weight, softmaxattention1.cv6.conv_offset.bias, softmaxattention1.switch.weight, softmaxattention1.switch.bias, softmaxattention1.xfm.h0_col, softmaxattention1.xfm.h1_col, softmaxattention1.xfm.h0_row, softmaxattention1.xfm.h1_row, softmaxattention1.cv7.weight

2022-06-20 14:51:41,657 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-06-20 14:51:41,665 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.conv2.weight - torch.Size([64, 76, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.se1.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.se1.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.se2.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.se2.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv1.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv1.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv1.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv2.weight - torch.Size([2048, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv2.conv_offset.weight - torch.Size([18, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv3.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv3.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv3.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv5.weight - torch.Size([4096, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv5.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv5.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv6.weight - torch.Size([2048, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv6.conv_offset.weight - torch.Size([2, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.cv6.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.switch.weight - torch.Size([1, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer5.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.1.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer1.2.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.cv3.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.conv2.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.1.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.cv3.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.conv2.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.2.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.cv3.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.conv2.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer2.3.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.cv3.conv_offset.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.conv2.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.1.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.conv2.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.2.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.conv2.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.3.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.conv2.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.4.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.conv2.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer3.5.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.cv3.conv_offset.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.0.cv3.conv_offset.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.0.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.conv2.conv_offset.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.1.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.1.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.1.cv3.conv_offset.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.1.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.conv2.conv_offset.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.2.conv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in xiaobo_DetectoRS_ResNet  

backbone.layer4.2.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.2.cv3.conv_offset.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer4.2.cv3.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.se1.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.se1.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.se2.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.se2.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv1.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv1.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv1.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv2.weight - torch.Size([2048, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv2.conv_offset.weight - torch.Size([18, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv3.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv3.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv3.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv5.weight - torch.Size([4096, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv5.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv5.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv6.weight - torch.Size([2048, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv6.conv_offset.weight - torch.Size([2, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv6.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.switch.weight - torch.Size([1, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.softmaxattention1.cv7.weight - torch.Size([4096, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.4.conv.weight - torch.Size([256, 4096, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.conv1.weight - torch.Size([64, 3, 7, 7]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.conv2.weight - torch.Size([64, 76, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.se1.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.se1.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.se2.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.se2.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.cv1.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.cv2.weight - torch.Size([2048, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.cv3.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.cv5.weight - torch.Size([4096, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.cv6.weight - torch.Size([2048, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.switch.weight - torch.Size([1, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer5.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.downsample.1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.downsample.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.cv3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.downsample.1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.downsample.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.rfp_conv.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.0.rfp_conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.cv3.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.downsample.1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.downsample.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.rfp_conv.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.0.rfp_conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.cv3.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.downsample.1.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.downsample.1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.rfp_conv.weight - torch.Size([2048, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer4.0.rfp_conv.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.cv3.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.se1.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.se1.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.se2.fc.0.weight - torch.Size([128, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.se2.fc.3.weight - torch.Size([2048, 128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv1.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv1.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv1.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv2.weight - torch.Size([2048, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv2.conv_offset.weight - torch.Size([18, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv2.conv_offset.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv3.weight - torch.Size([2048, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv3.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv3.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv5.weight - torch.Size([4096, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv5.conv_offset.weight - torch.Size([2, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv5.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv6.weight - torch.Size([2048, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv6.conv_offset.weight - torch.Size([2, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv6.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.switch.weight - torch.Size([1, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_modules.0.softmaxattention1.cv7.weight - torch.Size([4096, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.se1.fc.0.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.se1.fc.3.weight - torch.Size([256, 16]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.se2.fc.0.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.se2.fc.3.weight - torch.Size([256, 16]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv3.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv5.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv6.weight - torch.Size([2048, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv6.conv_offset.weight - torch.Size([2, 8192, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.cv6.conv_offset.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.switch.weight - torch.Size([1, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.softmaxattention.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.rfp_weight.weight - torch.Size([1, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_weight.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RFP  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([11, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([40, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([40]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 
2022-06-20 14:51:44,648 - mmdet - INFO - load checkpoint from /home/zh/zhao/mmdetection-2.18.0-new/voc_pretrained_resnet50_faster_weights_new_classes_7.pth
2022-06-20 14:51:44,649 - mmdet - INFO - Use load_from_local loader
2022-06-20 14:51:45,910 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([7, 1024]) from checkpoint, the shape in current model is torch.Size([11, 1024]).
size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([11]).
size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([80, 1024]) from checkpoint, the shape in current model is torch.Size([40, 1024]).
size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).
2022-06-20 14:51:45,950 - mmdet - INFO - Start running, host: zh@zh-Super-Server, work_dir: /home/zh/zhao/mmdetection-2.18.0-new/tools/work_dirs/cascade_rcnn_r50_rfp_1x_coco
2022-06-20 14:51:45,950 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-06-20 14:51:45,950 - mmdet - INFO - workflow: [('train', 1)], max: 14 epochs
2022-06-20 14:51:45,951 - mmdet - INFO - Checkpoints will be saved to /home/zh/zhao/mmdetection-2.18.0-new/tools/work_dirs/cascade_rcnn_r50_rfp_1x_coco by HardDiskBackend.
2022-06-20 14:52:26,510 - mmdet - INFO - Epoch [1][50/1604]	lr: 1.274e-04, eta: 5:02:49, time: 0.811, data_time: 0.051, memory: 8933, loss_rpn_cls: 0.2103, loss_rpn_bbox: 0.0153, loss_cls: 1.2283, acc: 83.4609, loss_bbox: 0.0618, loss: 1.5157
2022-06-20 14:52:56,229 - mmdet - INFO - Epoch [1][100/1604]	lr: 2.523e-04, eta: 4:21:48, time: 0.594, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.1035, loss_rpn_bbox: 0.0114, loss_cls: 0.1258, acc: 97.9062, loss_bbox: 0.0739, loss: 0.3146
2022-06-20 14:53:28,043 - mmdet - INFO - Epoch [1][150/1604]	lr: 3.771e-04, eta: 4:12:59, time: 0.636, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0515, loss_rpn_bbox: 0.0127, loss_cls: 0.1324, acc: 97.5859, loss_bbox: 0.0853, loss: 0.2820
2022-06-20 14:53:47,613 - mmdet - INFO - Epoch [1][200/1604]	lr: 5.020e-04, eta: 3:45:36, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0403, loss_rpn_bbox: 0.0136, loss_cls: 0.1375, acc: 97.6055, loss_bbox: 0.0887, loss: 0.2801
2022-06-20 14:54:07,355 - mmdet - INFO - Epoch [1][250/1604]	lr: 6.269e-04, eta: 3:29:18, time: 0.395, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0155, loss_rpn_bbox: 0.0090, loss_cls: 0.1862, acc: 96.5039, loss_bbox: 0.1305, loss: 0.3412
2022-06-20 14:54:26,913 - mmdet - INFO - Epoch [1][300/1604]	lr: 7.518e-04, eta: 3:18:06, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0088, loss_cls: 0.2086, acc: 95.6836, loss_bbox: 0.1584, loss: 0.3999
2022-06-20 14:54:49,929 - mmdet - INFO - Epoch [1][350/1604]	lr: 8.766e-04, eta: 3:13:39, time: 0.460, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0114, loss_cls: 0.2200, acc: 95.1758, loss_bbox: 0.1788, loss: 0.4313
2022-06-20 14:55:15,416 - mmdet - INFO - Epoch [1][400/1604]	lr: 1.002e-03, eta: 3:12:28, time: 0.510, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0136, loss_rpn_bbox: 0.0080, loss_cls: 0.1627, acc: 96.2305, loss_bbox: 0.1400, loss: 0.3243
2022-06-20 14:55:35,237 - mmdet - INFO - Epoch [1][450/1604]	lr: 1.126e-03, eta: 3:06:51, time: 0.396, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0103, loss_cls: 0.1792, acc: 95.8164, loss_bbox: 0.1504, loss: 0.3582
2022-06-20 14:55:57,328 - mmdet - INFO - Epoch [1][500/1604]	lr: 1.251e-03, eta: 3:03:57, time: 0.442, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0203, loss_rpn_bbox: 0.0088, loss_cls: 0.1678, acc: 96.1680, loss_bbox: 0.1406, loss: 0.3375
2022-06-20 14:56:17,193 - mmdet - INFO - Epoch [1][550/1604]	lr: 1.376e-03, eta: 3:00:02, time: 0.397, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0091, loss_cls: 0.1770, acc: 96.0664, loss_bbox: 0.1473, loss: 0.3507
2022-06-20 14:56:38,881 - mmdet - INFO - Epoch [1][600/1604]	lr: 1.501e-03, eta: 2:57:49, time: 0.434, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0097, loss_cls: 0.1900, acc: 95.4648, loss_bbox: 0.1625, loss: 0.3817
2022-06-20 14:57:04,825 - mmdet - INFO - Epoch [1][650/1604]	lr: 1.626e-03, eta: 2:58:16, time: 0.519, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.0071, loss_cls: 0.1392, acc: 96.4648, loss_bbox: 0.1245, loss: 0.2876
2022-06-20 14:57:27,658 - mmdet - INFO - Epoch [1][700/1604]	lr: 1.751e-03, eta: 2:56:59, time: 0.457, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.0101, loss_cls: 0.1460, acc: 96.5938, loss_bbox: 0.1200, loss: 0.2998
2022-06-20 14:57:47,187 - mmdet - INFO - Epoch [1][750/1604]	lr: 1.876e-03, eta: 2:54:14, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0103, loss_cls: 0.1533, acc: 96.0156, loss_bbox: 0.1306, loss: 0.3145
2022-06-20 14:58:10,787 - mmdet - INFO - Epoch [1][800/1604]	lr: 2.001e-03, eta: 2:53:36, time: 0.472, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0105, loss_cls: 0.1274, acc: 96.6641, loss_bbox: 0.1132, loss: 0.2729
2022-06-20 14:58:30,346 - mmdet - INFO - Epoch [1][850/1604]	lr: 2.125e-03, eta: 2:51:18, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0108, loss_cls: 0.1678, acc: 96.1406, loss_bbox: 0.1266, loss: 0.3183
2022-06-20 14:58:51,671 - mmdet - INFO - Epoch [1][900/1604]	lr: 2.250e-03, eta: 2:49:55, time: 0.426, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0144, loss_rpn_bbox: 0.0096, loss_cls: 0.1869, acc: 95.6016, loss_bbox: 0.1470, loss: 0.3579
2022-06-20 14:59:13,561 - mmdet - INFO - Epoch [1][950/1604]	lr: 2.375e-03, eta: 2:48:52, time: 0.438, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0062, loss_cls: 0.1152, acc: 96.6445, loss_bbox: 0.1084, loss: 0.2379
2022-06-20 14:59:50,277 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 14:59:50,277 - mmdet - INFO - Epoch [1][1000/1604]	lr: 2.500e-03, eta: 2:53:11, time: 0.734, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.0090, loss_cls: 0.1192, acc: 96.7617, loss_bbox: 0.1093, loss: 0.2561
2022-06-20 15:00:11,571 - mmdet - INFO - Epoch [1][1050/1604]	lr: 2.625e-03, eta: 2:51:47, time: 0.426, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0068, loss_cls: 0.1051, acc: 97.1133, loss_bbox: 0.0908, loss: 0.2103
2022-06-20 15:00:32,574 - mmdet - INFO - Epoch [1][1100/1604]	lr: 2.750e-03, eta: 2:50:23, time: 0.420, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0126, loss_cls: 0.1199, acc: 97.0117, loss_bbox: 0.1070, loss: 0.2637
2022-06-20 15:01:01,628 - mmdet - INFO - Epoch [1][1150/1604]	lr: 2.875e-03, eta: 2:51:34, time: 0.581, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0089, loss_cls: 0.1018, acc: 96.9219, loss_bbox: 0.0992, loss: 0.2230
2022-06-20 15:01:23,492 - mmdet - INFO - Epoch [1][1200/1604]	lr: 3.000e-03, eta: 2:50:29, time: 0.437, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0065, loss_cls: 0.1221, acc: 96.6953, loss_bbox: 0.1017, loss: 0.2462
2022-06-20 15:01:50,682 - mmdet - INFO - Epoch [1][1250/1604]	lr: 3.124e-03, eta: 2:50:58, time: 0.544, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0109, loss_cls: 0.1260, acc: 96.2969, loss_bbox: 0.1253, loss: 0.2691
2022-06-20 15:02:11,752 - mmdet - INFO - Epoch [1][1300/1604]	lr: 3.249e-03, eta: 2:49:43, time: 0.421, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0081, loss_cls: 0.1372, acc: 96.6797, loss_bbox: 0.1081, loss: 0.2753
2022-06-20 15:02:31,502 - mmdet - INFO - Epoch [1][1350/1604]	lr: 3.374e-03, eta: 2:48:12, time: 0.395, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0080, loss_cls: 0.1447, acc: 96.5234, loss_bbox: 0.1135, loss: 0.2820
2022-06-20 15:02:51,135 - mmdet - INFO - Epoch [1][1400/1604]	lr: 3.499e-03, eta: 2:46:43, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0075, loss_cls: 0.1128, acc: 96.7734, loss_bbox: 0.1122, loss: 0.2425
2022-06-20 15:03:10,674 - mmdet - INFO - Epoch [1][1450/1604]	lr: 3.624e-03, eta: 2:45:19, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0367, loss_rpn_bbox: 0.0101, loss_cls: 0.1315, acc: 96.3672, loss_bbox: 0.1183, loss: 0.2966
2022-06-20 15:03:30,340 - mmdet - INFO - Epoch [1][1500/1604]	lr: 3.749e-03, eta: 2:44:00, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0508, loss_rpn_bbox: 0.0127, loss_cls: 0.1264, acc: 96.8516, loss_bbox: 0.0943, loss: 0.2841
2022-06-20 15:04:02,707 - mmdet - INFO - Epoch [1][1550/1604]	lr: 3.874e-03, eta: 2:45:36, time: 0.647, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0295, loss_rpn_bbox: 0.0176, loss_cls: 0.1114, acc: 97.3125, loss_bbox: 0.0928, loss: 0.2513
2022-06-20 15:04:32,858 - mmdet - INFO - Epoch [1][1600/1604]	lr: 3.999e-03, eta: 2:46:36, time: 0.603, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0057, loss_cls: 0.1031, acc: 97.1016, loss_bbox: 0.1138, loss: 0.2342
2022-06-20 15:04:37,320 - mmdet - INFO - Saving checkpoint at 1 epochs
2022-06-20 15:06:34,779 - mmdet - INFO - Evaluating bbox...
2022-06-20 15:06:36,100 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.335 | 2_hanfeng | 0.236 | 3_yueyawan | 0.480 |
| 4_shuiban   | 0.329 | 5_youban  | 0.137 | 6_siban    | 0.089 |
| 7_yiwu      | 0.051 | 8_yahen   | 0.000 | 9_zhehen   | 0.000 |
| 10_yaozhe   | 0.011 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 15:06:36,123 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 15:06:36,124 - mmdet - INFO - Epoch(val) [1][688]	bbox_mAP: 0.1670, bbox_mAP_50: 0.3950, bbox_mAP_75: 0.1200, bbox_mAP_s: 0.0220, bbox_mAP_m: 0.1360, bbox_mAP_l: 0.1770, bbox_mAP_copypaste: 0.167 0.395 0.120 0.022 0.136 0.177
2022-06-20 15:07:00,893 - mmdet - INFO - Epoch [2][50/1604]	lr: 4.133e-03, eta: 2:45:56, time: 0.495, data_time: 0.049, memory: 8933, loss_rpn_cls: 0.0121, loss_rpn_bbox: 0.0057, loss_cls: 0.1047, acc: 97.1016, loss_bbox: 0.1074, loss: 0.2299
2022-06-20 15:07:22,135 - mmdet - INFO - Epoch [2][100/1604]	lr: 4.258e-03, eta: 2:44:59, time: 0.425, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0131, loss_cls: 0.1135, acc: 96.8711, loss_bbox: 0.1071, loss: 0.2507
2022-06-20 15:07:48,301 - mmdet - INFO - Epoch [2][150/1604]	lr: 4.383e-03, eta: 2:45:02, time: 0.523, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0086, loss_cls: 0.1509, acc: 95.8477, loss_bbox: 0.1317, loss: 0.3022
2022-06-20 15:08:10,751 - mmdet - INFO - Epoch [2][200/1604]	lr: 4.508e-03, eta: 2:44:22, time: 0.449, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0079, loss_cls: 0.1163, acc: 96.6016, loss_bbox: 0.1155, loss: 0.2461
2022-06-20 15:08:37,373 - mmdet - INFO - Epoch [2][250/1604]	lr: 4.633e-03, eta: 2:44:28, time: 0.532, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0120, loss_rpn_bbox: 0.0078, loss_cls: 0.0955, acc: 97.0781, loss_bbox: 0.1087, loss: 0.2241
2022-06-20 15:09:09,984 - mmdet - INFO - Epoch [2][300/1604]	lr: 4.758e-03, eta: 2:45:38, time: 0.652, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0052, loss_cls: 0.0877, acc: 97.1797, loss_bbox: 0.1086, loss: 0.2070
2022-06-20 15:09:30,365 - mmdet - INFO - Epoch [2][350/1604]	lr: 4.883e-03, eta: 2:44:34, time: 0.408, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0060, loss_cls: 0.0961, acc: 97.0391, loss_bbox: 0.1048, loss: 0.2167
2022-06-20 15:09:54,364 - mmdet - INFO - Epoch [2][400/1604]	lr: 5.000e-03, eta: 2:44:09, time: 0.480, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0107, loss_rpn_bbox: 0.0153, loss_cls: 0.1495, acc: 95.9492, loss_bbox: 0.1327, loss: 0.3081
2022-06-20 15:10:22,245 - mmdet - INFO - Epoch [2][450/1604]	lr: 5.000e-03, eta: 2:44:23, time: 0.558, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.0121, loss_cls: 0.1194, acc: 96.4453, loss_bbox: 0.1319, loss: 0.2797
2022-06-20 15:10:48,668 - mmdet - INFO - Epoch [2][500/1604]	lr: 5.000e-03, eta: 2:44:20, time: 0.528, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0148, loss_cls: 0.1280, acc: 96.2578, loss_bbox: 0.1237, loss: 0.2802
2022-06-20 15:11:09,108 - mmdet - INFO - Epoch [2][550/1604]	lr: 5.000e-03, eta: 2:43:20, time: 0.409, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0143, loss_cls: 0.1347, acc: 96.3242, loss_bbox: 0.1262, loss: 0.2903
2022-06-20 15:11:42,447 - mmdet - INFO - Epoch [2][600/1604]	lr: 5.000e-03, eta: 2:44:21, time: 0.667, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0075, loss_cls: 0.1077, acc: 96.9883, loss_bbox: 0.1000, loss: 0.2258
2022-06-20 15:12:18,059 - mmdet - INFO - Epoch [2][650/1604]	lr: 5.000e-03, eta: 2:45:37, time: 0.712, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0119, loss_rpn_bbox: 0.0078, loss_cls: 0.1275, acc: 96.7383, loss_bbox: 0.1155, loss: 0.2627
2022-06-20 15:12:37,867 - mmdet - INFO - Epoch [2][700/1604]	lr: 5.000e-03, eta: 2:44:31, time: 0.396, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0074, loss_cls: 0.1125, acc: 96.5898, loss_bbox: 0.1132, loss: 0.2419
2022-06-20 15:13:06,365 - mmdet - INFO - Epoch [2][750/1604]	lr: 5.000e-03, eta: 2:44:40, time: 0.570, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.0086, loss_cls: 0.1358, acc: 96.7578, loss_bbox: 0.1121, loss: 0.2729
2022-06-20 15:13:29,358 - mmdet - INFO - Epoch [2][800/1604]	lr: 5.000e-03, eta: 2:44:03, time: 0.460, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0046, loss_cls: 0.1023, acc: 97.3398, loss_bbox: 0.0872, loss: 0.2014
2022-06-20 15:13:52,434 - mmdet - INFO - Epoch [2][850/1604]	lr: 5.000e-03, eta: 2:43:26, time: 0.462, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0078, loss_cls: 0.0967, acc: 96.8164, loss_bbox: 0.1063, loss: 0.2190
2022-06-20 15:14:13,794 - mmdet - INFO - Epoch [2][900/1604]	lr: 5.000e-03, eta: 2:42:37, time: 0.427, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0056, loss_cls: 0.0879, acc: 97.1992, loss_bbox: 0.0996, loss: 0.1997
2022-06-20 15:14:36,826 - mmdet - INFO - Epoch [2][950/1604]	lr: 5.000e-03, eta: 2:42:01, time: 0.461, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.0092, loss_cls: 0.1249, acc: 96.5781, loss_bbox: 0.1157, loss: 0.2631
2022-06-20 15:14:58,026 - mmdet - INFO - Epoch [2][1000/1604]	lr: 5.000e-03, eta: 2:41:12, time: 0.424, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0078, loss_cls: 0.1021, acc: 96.6523, loss_bbox: 0.1066, loss: 0.2250
2022-06-20 15:15:22,006 - mmdet - INFO - Epoch [2][1050/1604]	lr: 5.000e-03, eta: 2:40:45, time: 0.480, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0052, loss_cls: 0.1059, acc: 96.7461, loss_bbox: 0.1081, loss: 0.2298
2022-06-20 15:15:48,510 - mmdet - INFO - Epoch [2][1100/1604]	lr: 5.000e-03, eta: 2:40:36, time: 0.530, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0119, loss_rpn_bbox: 0.0097, loss_cls: 0.1160, acc: 96.4336, loss_bbox: 0.1208, loss: 0.2583
2022-06-20 15:16:11,389 - mmdet - INFO - Epoch [2][1150/1604]	lr: 5.000e-03, eta: 2:40:01, time: 0.458, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0081, loss_cls: 0.1205, acc: 96.3008, loss_bbox: 0.1226, loss: 0.2601
2022-06-20 15:16:33,575 - mmdet - INFO - Epoch [2][1200/1604]	lr: 5.000e-03, eta: 2:39:21, time: 0.444, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0091, loss_cls: 0.1283, acc: 96.1914, loss_bbox: 0.1141, loss: 0.2618
2022-06-20 15:16:59,924 - mmdet - INFO - Epoch [2][1250/1604]	lr: 5.000e-03, eta: 2:39:11, time: 0.527, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0077, loss_cls: 0.1154, acc: 96.3711, loss_bbox: 0.1215, loss: 0.2525
2022-06-20 15:17:21,467 - mmdet - INFO - Epoch [2][1300/1604]	lr: 5.000e-03, eta: 2:38:27, time: 0.431, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0102, loss_rpn_bbox: 0.0060, loss_cls: 0.1167, acc: 96.5195, loss_bbox: 0.1138, loss: 0.2467
2022-06-20 15:17:41,003 - mmdet - INFO - Epoch [2][1350/1604]	lr: 5.000e-03, eta: 2:37:32, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0089, loss_cls: 0.1216, acc: 96.2930, loss_bbox: 0.1216, loss: 0.2621
2022-06-20 15:18:02,306 - mmdet - INFO - Epoch [2][1400/1604]	lr: 5.000e-03, eta: 2:36:48, time: 0.426, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0098, loss_cls: 0.1053, acc: 96.7656, loss_bbox: 0.1044, loss: 0.2276
2022-06-20 15:18:25,293 - mmdet - INFO - Epoch [2][1450/1604]	lr: 5.000e-03, eta: 2:36:17, time: 0.460, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0125, loss_rpn_bbox: 0.0084, loss_cls: 0.0870, acc: 97.4219, loss_bbox: 0.0836, loss: 0.1915
2022-06-20 15:18:47,190 - mmdet - INFO - Epoch [2][1500/1604]	lr: 5.000e-03, eta: 2:35:38, time: 0.438, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0053, loss_cls: 0.0911, acc: 97.2734, loss_bbox: 0.0981, loss: 0.2019
2022-06-20 15:19:12,956 - mmdet - INFO - Epoch [2][1550/1604]	lr: 5.000e-03, eta: 2:35:24, time: 0.515, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0109, loss_cls: 0.0977, acc: 96.8633, loss_bbox: 0.1017, loss: 0.2276
2022-06-20 15:19:32,896 - mmdet - INFO - Epoch [2][1600/1604]	lr: 5.000e-03, eta: 2:34:35, time: 0.399, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0426, loss_rpn_bbox: 0.0128, loss_cls: 0.0954, acc: 97.0352, loss_bbox: 0.0979, loss: 0.2487
2022-06-20 15:19:34,562 - mmdet - INFO - Saving checkpoint at 2 epochs
2022-06-20 15:21:37,319 - mmdet - INFO - Evaluating bbox...
2022-06-20 15:21:38,432 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.472 | 2_hanfeng | 0.026 | 3_yueyawan | 0.464 |
| 4_shuiban   | 0.276 | 5_youban  | 0.182 | 6_siban    | 0.150 |
| 7_yiwu      | 0.039 | 8_yahen   | 0.040 | 9_zhehen   | 0.062 |
| 10_yaozhe   | 0.004 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 15:21:38,525 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 15:21:38,527 - mmdet - INFO - Epoch(val) [2][688]	bbox_mAP: 0.1710, bbox_mAP_50: 0.3740, bbox_mAP_75: 0.1310, bbox_mAP_s: 0.0550, bbox_mAP_m: 0.1830, bbox_mAP_l: 0.1650, bbox_mAP_copypaste: 0.171 0.374 0.131 0.055 0.183 0.165
2022-06-20 15:22:04,452 - mmdet - INFO - Epoch [3][50/1604]	lr: 5.000e-03, eta: 2:34:08, time: 0.517, data_time: 0.052, memory: 8933, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0070, loss_cls: 0.0892, acc: 97.2773, loss_bbox: 0.0921, loss: 0.2001
2022-06-20 15:22:31,934 - mmdet - INFO - Epoch [3][100/1604]	lr: 5.000e-03, eta: 2:34:03, time: 0.550, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0124, loss_cls: 0.0786, acc: 97.4180, loss_bbox: 0.0808, loss: 0.1877
2022-06-20 15:22:53,180 - mmdet - INFO - Epoch [3][150/1604]	lr: 5.000e-03, eta: 2:33:23, time: 0.425, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0179, loss_rpn_bbox: 0.0094, loss_cls: 0.0667, acc: 97.7422, loss_bbox: 0.0950, loss: 0.1890
2022-06-20 15:23:16,983 - mmdet - INFO - Epoch [3][200/1604]	lr: 5.000e-03, eta: 2:32:57, time: 0.476, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0048, loss_cls: 0.1037, acc: 97.0391, loss_bbox: 0.0913, loss: 0.2129
2022-06-20 15:23:36,839 - mmdet - INFO - Epoch [3][250/1604]	lr: 5.000e-03, eta: 2:32:10, time: 0.397, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0081, loss_cls: 0.0985, acc: 97.1445, loss_bbox: 0.1019, loss: 0.2170
2022-06-20 15:23:57,378 - mmdet - INFO - Epoch [3][300/1604]	lr: 5.000e-03, eta: 2:31:27, time: 0.411, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0070, loss_cls: 0.0816, acc: 97.1992, loss_bbox: 0.1038, loss: 0.2027
2022-06-20 15:24:22,264 - mmdet - INFO - Epoch [3][350/1604]	lr: 5.000e-03, eta: 2:31:08, time: 0.498, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0061, loss_cls: 0.0890, acc: 96.9258, loss_bbox: 0.1104, loss: 0.2125
2022-06-20 15:24:42,032 - mmdet - INFO - Epoch [3][400/1604]	lr: 5.000e-03, eta: 2:30:22, time: 0.395, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0071, loss_cls: 0.0875, acc: 97.0859, loss_bbox: 0.0932, loss: 0.1973
2022-06-20 15:25:05,888 - mmdet - INFO - Epoch [3][450/1604]	lr: 5.000e-03, eta: 2:29:57, time: 0.477, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0081, loss_cls: 0.0854, acc: 97.3125, loss_bbox: 0.0986, loss: 0.1967
2022-06-20 15:25:25,782 - mmdet - INFO - Epoch [3][500/1604]	lr: 5.000e-03, eta: 2:29:13, time: 0.398, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0086, loss_cls: 0.0765, acc: 97.4688, loss_bbox: 0.0954, loss: 0.1860
2022-06-20 15:25:47,177 - mmdet - INFO - Epoch [3][550/1604]	lr: 5.000e-03, eta: 2:28:37, time: 0.428, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0048, loss_cls: 0.0810, acc: 97.2344, loss_bbox: 0.0950, loss: 0.1889
2022-06-20 15:26:13,849 - mmdet - INFO - Epoch [3][600/1604]	lr: 5.000e-03, eta: 2:28:27, time: 0.533, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0061, loss_cls: 0.0847, acc: 97.2969, loss_bbox: 0.0917, loss: 0.1900
2022-06-20 15:26:33,738 - mmdet - INFO - Epoch [3][650/1604]	lr: 5.000e-03, eta: 2:27:43, time: 0.398, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0077, loss_cls: 0.0962, acc: 96.6836, loss_bbox: 0.1220, loss: 0.2363
2022-06-20 15:26:57,498 - mmdet - INFO - Epoch [3][700/1604]	lr: 5.000e-03, eta: 2:27:19, time: 0.475, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0091, loss_rpn_bbox: 0.0055, loss_cls: 0.1038, acc: 96.9414, loss_bbox: 0.0972, loss: 0.2156
2022-06-20 15:27:18,229 - mmdet - INFO - Epoch [3][750/1604]	lr: 5.000e-03, eta: 2:26:41, time: 0.415, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0118, loss_cls: 0.1183, acc: 96.6836, loss_bbox: 0.1043, loss: 0.2476
2022-06-20 15:27:48,898 - mmdet - INFO - Epoch [3][800/1604]	lr: 5.000e-03, eta: 2:26:49, time: 0.613, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0089, loss_cls: 0.0932, acc: 97.1719, loss_bbox: 0.1003, loss: 0.2178
2022-06-20 15:28:08,723 - mmdet - INFO - Epoch [3][850/1604]	lr: 5.000e-03, eta: 2:26:07, time: 0.396, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0061, loss_cls: 0.1023, acc: 96.8672, loss_bbox: 0.1001, loss: 0.2188
2022-06-20 15:28:36,036 - mmdet - INFO - Epoch [3][900/1604]	lr: 5.000e-03, eta: 2:25:58, time: 0.546, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0068, loss_cls: 0.0760, acc: 97.4531, loss_bbox: 0.0906, loss: 0.1802
2022-06-20 15:29:01,409 - mmdet - INFO - Epoch [3][950/1604]	lr: 5.000e-03, eta: 2:25:41, time: 0.507, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0138, loss_rpn_bbox: 0.0105, loss_cls: 0.1153, acc: 96.3047, loss_bbox: 0.1275, loss: 0.2671
2022-06-20 15:29:22,808 - mmdet - INFO - Epoch [3][1000/1604]	lr: 5.000e-03, eta: 2:25:06, time: 0.428, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0076, loss_cls: 0.0903, acc: 97.0625, loss_bbox: 0.0956, loss: 0.2031
2022-06-20 15:29:47,146 - mmdet - INFO - Epoch [3][1050/1604]	lr: 5.000e-03, eta: 2:24:45, time: 0.487, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0082, loss_cls: 0.0886, acc: 97.0273, loss_bbox: 0.0936, loss: 0.1972
2022-06-20 15:30:09,669 - mmdet - INFO - Epoch [3][1100/1604]	lr: 5.000e-03, eta: 2:24:15, time: 0.450, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0068, loss_cls: 0.1097, acc: 96.1914, loss_bbox: 0.1155, loss: 0.2391
2022-06-20 15:30:35,938 - mmdet - INFO - Epoch [3][1150/1604]	lr: 5.000e-03, eta: 2:24:01, time: 0.525, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0221, loss_cls: 0.0933, acc: 96.8203, loss_bbox: 0.1086, loss: 0.2352
2022-06-20 15:30:57,779 - mmdet - INFO - Epoch [3][1200/1604]	lr: 5.000e-03, eta: 2:23:29, time: 0.437, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0114, loss_cls: 0.1132, acc: 96.5625, loss_bbox: 0.1108, loss: 0.2429
2022-06-20 15:31:23,034 - mmdet - INFO - Epoch [3][1250/1604]	lr: 5.000e-03, eta: 2:23:11, time: 0.505, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0062, loss_cls: 0.0995, acc: 96.4062, loss_bbox: 0.1200, loss: 0.2343
2022-06-20 15:31:45,116 - mmdet - INFO - Epoch [3][1300/1604]	lr: 5.000e-03, eta: 2:22:40, time: 0.442, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0060, loss_cls: 0.1076, acc: 96.4883, loss_bbox: 0.1047, loss: 0.2241
2022-06-20 15:32:08,588 - mmdet - INFO - Epoch [3][1350/1604]	lr: 5.000e-03, eta: 2:22:15, time: 0.469, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0065, loss_cls: 0.1030, acc: 96.5430, loss_bbox: 0.1156, loss: 0.2303
2022-06-20 15:32:30,483 - mmdet - INFO - Epoch [3][1400/1604]	lr: 5.000e-03, eta: 2:21:43, time: 0.438, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0085, loss_cls: 0.1046, acc: 96.6367, loss_bbox: 0.1131, loss: 0.2413
2022-06-20 15:32:56,795 - mmdet - INFO - Epoch [3][1450/1604]	lr: 5.000e-03, eta: 2:21:29, time: 0.526, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0075, loss_cls: 0.0894, acc: 97.0312, loss_bbox: 0.1001, loss: 0.2039
2022-06-20 15:33:21,154 - mmdet - INFO - Epoch [3][1500/1604]	lr: 5.000e-03, eta: 2:21:07, time: 0.487, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0068, loss_cls: 0.0873, acc: 97.0273, loss_bbox: 0.1111, loss: 0.2132
2022-06-20 15:33:40,765 - mmdet - INFO - Epoch [3][1550/1604]	lr: 5.000e-03, eta: 2:20:27, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0069, loss_cls: 0.1058, acc: 96.6445, loss_bbox: 0.1069, loss: 0.2245
2022-06-20 15:34:04,585 - mmdet - INFO - Epoch [3][1600/1604]	lr: 5.000e-03, eta: 2:20:04, time: 0.476, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0071, loss_cls: 0.1075, acc: 96.6289, loss_bbox: 0.1064, loss: 0.2281
2022-06-20 15:34:06,315 - mmdet - INFO - Saving checkpoint at 3 epochs
2022-06-20 15:35:42,682 - mmdet - INFO - Evaluating bbox...
2022-06-20 15:35:43,768 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.522 | 2_hanfeng | 0.159 | 3_yueyawan | 0.525 |
| 4_shuiban   | 0.378 | 5_youban  | 0.199 | 6_siban    | 0.212 |
| 7_yiwu      | 0.059 | 8_yahen   | 0.070 | 9_zhehen   | 0.090 |
| 10_yaozhe   | 0.273 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 15:35:43,783 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 15:35:43,784 - mmdet - INFO - Epoch(val) [3][688]	bbox_mAP: 0.2490, bbox_mAP_50: 0.5650, bbox_mAP_75: 0.1880, bbox_mAP_s: 0.1170, bbox_mAP_m: 0.2080, bbox_mAP_l: 0.2460, bbox_mAP_copypaste: 0.249 0.565 0.188 0.117 0.208 0.246
2022-06-20 15:36:08,211 - mmdet - INFO - Epoch [4][50/1604]	lr: 5.000e-03, eta: 2:19:33, time: 0.488, data_time: 0.048, memory: 8933, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0071, loss_cls: 0.0808, acc: 97.1719, loss_bbox: 0.1098, loss: 0.2067
2022-06-20 15:36:32,872 - mmdet - INFO - Epoch [4][100/1604]	lr: 5.000e-03, eta: 2:19:12, time: 0.493, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0063, loss_cls: 0.0890, acc: 96.8984, loss_bbox: 0.1035, loss: 0.2077
2022-06-20 15:36:52,520 - mmdet - INFO - Epoch [4][150/1604]	lr: 5.000e-03, eta: 2:18:34, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0084, loss_cls: 0.1129, acc: 96.4805, loss_bbox: 0.1088, loss: 0.2375
2022-06-20 15:37:12,197 - mmdet - INFO - Epoch [4][200/1604]	lr: 5.000e-03, eta: 2:17:56, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0076, loss_cls: 0.0855, acc: 96.9766, loss_bbox: 0.1097, loss: 0.2110
2022-06-20 15:37:35,510 - mmdet - INFO - Epoch [4][250/1604]	lr: 5.000e-03, eta: 2:17:31, time: 0.466, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0070, loss_cls: 0.0851, acc: 97.1016, loss_bbox: 0.1013, loss: 0.1990
2022-06-20 15:37:59,034 - mmdet - INFO - Epoch [4][300/1604]	lr: 5.000e-03, eta: 2:17:06, time: 0.470, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0060, loss_cls: 0.0906, acc: 96.8867, loss_bbox: 0.1219, loss: 0.2240
2022-06-20 15:38:23,545 - mmdet - INFO - Epoch [4][350/1604]	lr: 5.000e-03, eta: 2:16:45, time: 0.490, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0066, loss_cls: 0.1197, acc: 96.6055, loss_bbox: 0.1197, loss: 0.2524
2022-06-20 15:38:43,470 - mmdet - INFO - Epoch [4][400/1604]	lr: 5.000e-03, eta: 2:16:09, time: 0.399, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0059, loss_cls: 0.1094, acc: 96.2930, loss_bbox: 0.1244, loss: 0.2451
2022-06-20 15:39:04,848 - mmdet - INFO - Epoch [4][450/1604]	lr: 5.000e-03, eta: 2:15:38, time: 0.427, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0057, loss_cls: 0.1032, acc: 96.9805, loss_bbox: 0.1044, loss: 0.2212
2022-06-20 15:39:32,178 - mmdet - INFO - Epoch [4][500/1604]	lr: 5.000e-03, eta: 2:15:26, time: 0.547, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0067, loss_cls: 0.1063, acc: 96.5625, loss_bbox: 0.1259, loss: 0.2439
2022-06-20 15:39:56,320 - mmdet - INFO - Epoch [4][550/1604]	lr: 5.000e-03, eta: 2:15:04, time: 0.483, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0067, loss_cls: 0.0741, acc: 97.3047, loss_bbox: 0.0910, loss: 0.1757
2022-06-20 15:40:21,144 - mmdet - INFO - Epoch [4][600/1604]	lr: 5.000e-03, eta: 2:14:44, time: 0.496, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0073, loss_cls: 0.0894, acc: 96.6172, loss_bbox: 0.1031, loss: 0.2057
2022-06-20 15:40:50,123 - mmdet - INFO - Epoch [4][650/1604]	lr: 5.000e-03, eta: 2:14:36, time: 0.580, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0047, loss_cls: 0.0898, acc: 96.9531, loss_bbox: 0.1058, loss: 0.2062
2022-06-20 15:41:13,410 - mmdet - INFO - Epoch [4][700/1604]	lr: 5.000e-03, eta: 2:14:11, time: 0.466, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0046, loss_cls: 0.0748, acc: 97.2109, loss_bbox: 0.0996, loss: 0.1839
2022-06-20 15:41:33,533 - mmdet - INFO - Epoch [4][750/1604]	lr: 5.000e-03, eta: 2:13:36, time: 0.403, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0065, loss_cls: 0.0954, acc: 96.5469, loss_bbox: 0.1222, loss: 0.2304
2022-06-20 15:42:22,156 - mmdet - INFO - Epoch [4][800/1604]	lr: 5.000e-03, eta: 2:14:27, time: 0.972, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0053, loss_cls: 0.1066, acc: 96.4648, loss_bbox: 0.1094, loss: 0.2264
2022-06-20 15:42:45,515 - mmdet - INFO - Epoch [4][850/1604]	lr: 5.000e-03, eta: 2:14:01, time: 0.467, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0054, loss_cls: 0.0984, acc: 96.6836, loss_bbox: 0.1144, loss: 0.2228
2022-06-20 15:43:05,394 - mmdet - INFO - Epoch [4][900/1604]	lr: 5.000e-03, eta: 2:13:26, time: 0.398, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0064, loss_cls: 0.0849, acc: 97.2891, loss_bbox: 0.0946, loss: 0.1926
2022-06-20 15:43:24,992 - mmdet - INFO - Epoch [4][950/1604]	lr: 5.000e-03, eta: 2:12:49, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0070, loss_cls: 0.1107, acc: 96.3828, loss_bbox: 0.1240, loss: 0.2489
2022-06-20 15:43:48,400 - mmdet - INFO - Epoch [4][1000/1604]	lr: 5.000e-03, eta: 2:12:24, time: 0.468, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0072, loss_cls: 0.1127, acc: 96.6719, loss_bbox: 0.1094, loss: 0.2474
2022-06-20 15:44:12,572 - mmdet - INFO - Epoch [4][1050/1604]	lr: 5.000e-03, eta: 2:12:01, time: 0.483, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0123, loss_cls: 0.0796, acc: 97.2227, loss_bbox: 0.0970, loss: 0.1957
2022-06-20 15:44:34,184 - mmdet - INFO - Epoch [4][1100/1604]	lr: 5.000e-03, eta: 2:11:31, time: 0.432, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0052, loss_cls: 0.0912, acc: 96.8984, loss_bbox: 0.1137, loss: 0.2171
2022-06-20 15:45:00,821 - mmdet - INFO - Epoch [4][1150/1604]	lr: 5.000e-03, eta: 2:11:15, time: 0.533, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0127, loss_rpn_bbox: 0.0085, loss_cls: 0.0945, acc: 96.9414, loss_bbox: 0.0998, loss: 0.2155
2022-06-20 15:45:22,073 - mmdet - INFO - Epoch [4][1200/1604]	lr: 5.000e-03, eta: 2:10:44, time: 0.425, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0057, loss_cls: 0.0963, acc: 97.0352, loss_bbox: 0.0986, loss: 0.2064
2022-06-20 15:45:48,014 - mmdet - INFO - Epoch [4][1250/1604]	lr: 5.000e-03, eta: 2:10:25, time: 0.519, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0120, loss_cls: 0.0801, acc: 97.0898, loss_bbox: 0.1066, loss: 0.2050
2022-06-20 15:46:10,706 - mmdet - INFO - Epoch [4][1300/1604]	lr: 5.000e-03, eta: 2:09:58, time: 0.454, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0086, loss_cls: 0.0896, acc: 97.1562, loss_bbox: 0.0976, loss: 0.2034
2022-06-20 15:46:37,506 - mmdet - INFO - Epoch [4][1350/1604]	lr: 5.000e-03, eta: 2:09:42, time: 0.536, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0074, loss_cls: 0.0865, acc: 97.2578, loss_bbox: 0.0947, loss: 0.1972
2022-06-20 15:46:57,993 - mmdet - INFO - Epoch [4][1400/1604]	lr: 5.000e-03, eta: 2:09:10, time: 0.410, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0067, loss_cls: 0.1159, acc: 96.2461, loss_bbox: 0.1265, loss: 0.2533
2022-06-20 15:47:22,391 - mmdet - INFO - Epoch [4][1450/1604]	lr: 5.000e-03, eta: 2:08:47, time: 0.488, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0107, loss_cls: 0.0866, acc: 97.1289, loss_bbox: 0.0886, loss: 0.1960
2022-06-20 15:47:44,900 - mmdet - INFO - Epoch [4][1500/1604]	lr: 5.000e-03, eta: 2:08:20, time: 0.450, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0064, loss_cls: 0.0933, acc: 96.9062, loss_bbox: 0.0996, loss: 0.2055
2022-06-20 15:48:04,384 - mmdet - INFO - Epoch [4][1550/1604]	lr: 5.000e-03, eta: 2:07:45, time: 0.390, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0071, loss_cls: 0.0908, acc: 97.0117, loss_bbox: 0.1072, loss: 0.2140
2022-06-20 15:48:27,226 - mmdet - INFO - Epoch [4][1600/1604]	lr: 5.000e-03, eta: 2:07:19, time: 0.457, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0079, loss_cls: 0.1079, acc: 96.1445, loss_bbox: 0.1191, loss: 0.2404
2022-06-20 15:48:28,861 - mmdet - INFO - Saving checkpoint at 4 epochs
2022-06-20 15:49:58,855 - mmdet - INFO - Evaluating bbox...
2022-06-20 15:49:59,921 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.376 | 2_hanfeng | 0.453 | 3_yueyawan | 0.528 |
| 4_shuiban   | 0.282 | 5_youban  | 0.178 | 6_siban    | 0.237 |
| 7_yiwu      | 0.051 | 8_yahen   | 0.021 | 9_zhehen   | 0.103 |
| 10_yaozhe   | 0.244 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 15:49:59,957 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 15:49:59,958 - mmdet - INFO - Epoch(val) [4][688]	bbox_mAP: 0.2470, bbox_mAP_50: 0.5690, bbox_mAP_75: 0.1660, bbox_mAP_s: 0.2750, bbox_mAP_m: 0.1960, bbox_mAP_l: 0.2330, bbox_mAP_copypaste: 0.247 0.569 0.166 0.275 0.196 0.233
2022-06-20 15:50:23,334 - mmdet - INFO - Epoch [5][50/1604]	lr: 5.000e-03, eta: 2:06:47, time: 0.467, data_time: 0.048, memory: 8933, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0122, loss_cls: 0.0804, acc: 97.3711, loss_bbox: 0.0914, loss: 0.1897
2022-06-20 15:50:47,732 - mmdet - INFO - Epoch [5][100/1604]	lr: 5.000e-03, eta: 2:06:25, time: 0.488, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0058, loss_cls: 0.0866, acc: 96.9727, loss_bbox: 0.0911, loss: 0.1886
2022-06-20 15:51:12,674 - mmdet - INFO - Epoch [5][150/1604]	lr: 5.000e-03, eta: 2:06:04, time: 0.499, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0088, loss_cls: 0.1042, acc: 96.7109, loss_bbox: 0.1242, loss: 0.2468
2022-06-20 15:51:35,706 - mmdet - INFO - Epoch [5][200/1604]	lr: 5.000e-03, eta: 2:05:38, time: 0.461, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0114, loss_cls: 0.0903, acc: 96.6367, loss_bbox: 0.1196, loss: 0.2281
2022-06-20 15:51:55,521 - mmdet - INFO - Epoch [5][250/1604]	lr: 5.000e-03, eta: 2:05:05, time: 0.396, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0115, loss_cls: 0.0853, acc: 96.7852, loss_bbox: 0.1036, loss: 0.2048
2022-06-20 15:52:23,272 - mmdet - INFO - Epoch [5][300/1604]	lr: 5.000e-03, eta: 2:04:51, time: 0.555, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0053, loss_cls: 0.0800, acc: 97.3203, loss_bbox: 0.0977, loss: 0.1898
2022-06-20 15:52:43,196 - mmdet - INFO - Epoch [5][350/1604]	lr: 5.000e-03, eta: 2:04:18, time: 0.398, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0078, loss_cls: 0.1145, acc: 96.5156, loss_bbox: 0.1208, loss: 0.2479
2022-06-20 15:53:11,319 - mmdet - INFO - Epoch [5][400/1604]	lr: 5.000e-03, eta: 2:04:04, time: 0.562, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0093, loss_cls: 0.0910, acc: 96.9258, loss_bbox: 0.1058, loss: 0.2121
2022-06-20 15:53:31,506 - mmdet - INFO - Epoch [5][450/1604]	lr: 5.000e-03, eta: 2:03:32, time: 0.404, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0054, loss_cls: 0.0749, acc: 97.2383, loss_bbox: 0.0930, loss: 0.1773
2022-06-20 15:53:51,217 - mmdet - INFO - Epoch [5][500/1604]	lr: 5.000e-03, eta: 2:02:59, time: 0.394, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0053, loss_cls: 0.0890, acc: 96.7031, loss_bbox: 0.1131, loss: 0.2128
2022-06-20 15:54:11,639 - mmdet - INFO - Epoch [5][550/1604]	lr: 5.000e-03, eta: 2:02:28, time: 0.408, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0075, loss_cls: 0.0778, acc: 96.9727, loss_bbox: 0.1007, loss: 0.1938
2022-06-20 15:54:34,709 - mmdet - INFO - Epoch [5][600/1604]	lr: 5.000e-03, eta: 2:02:03, time: 0.461, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0050, loss_cls: 0.0791, acc: 97.1602, loss_bbox: 0.0838, loss: 0.1732
2022-06-20 15:54:56,469 - mmdet - INFO - Epoch [5][650/1604]	lr: 5.000e-03, eta: 2:01:35, time: 0.435, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0056, loss_cls: 0.0752, acc: 97.1250, loss_bbox: 0.0964, loss: 0.1813
2022-06-20 15:55:18,676 - mmdet - INFO - Epoch [5][700/1604]	lr: 5.000e-03, eta: 2:01:08, time: 0.444, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0077, loss_cls: 0.0704, acc: 97.5352, loss_bbox: 0.0814, loss: 0.1632
2022-06-20 15:55:44,260 - mmdet - INFO - Epoch [5][750/1604]	lr: 5.000e-03, eta: 2:00:48, time: 0.512, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0069, loss_cls: 0.0805, acc: 97.0430, loss_bbox: 0.1079, loss: 0.2012
2022-06-20 15:56:04,262 - mmdet - INFO - Epoch [5][800/1604]	lr: 5.000e-03, eta: 2:00:17, time: 0.400, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0057, loss_cls: 0.0970, acc: 96.6680, loss_bbox: 0.1115, loss: 0.2202
2022-06-20 15:56:23,767 - mmdet - INFO - Epoch [5][850/1604]	lr: 5.000e-03, eta: 1:59:44, time: 0.390, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0071, loss_cls: 0.0936, acc: 96.6758, loss_bbox: 0.1113, loss: 0.2200
2022-06-20 15:56:43,345 - mmdet - INFO - Epoch [5][900/1604]	lr: 5.000e-03, eta: 1:59:12, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0053, loss_cls: 0.0844, acc: 96.9180, loss_bbox: 0.0944, loss: 0.1880
2022-06-20 15:57:03,841 - mmdet - INFO - Epoch [5][950/1604]	lr: 5.000e-03, eta: 1:58:42, time: 0.410, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0056, loss_cls: 0.0872, acc: 96.6602, loss_bbox: 0.1144, loss: 0.2116
2022-06-20 15:57:23,484 - mmdet - INFO - Epoch [5][1000/1604]	lr: 5.000e-03, eta: 1:58:11, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0061, loss_cls: 0.0801, acc: 96.9414, loss_bbox: 0.0979, loss: 0.1879
2022-06-20 15:57:43,136 - mmdet - INFO - Epoch [5][1050/1604]	lr: 5.000e-03, eta: 1:57:39, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0060, loss_cls: 0.0637, acc: 97.8320, loss_bbox: 0.0872, loss: 0.1616
2022-06-20 15:58:05,396 - mmdet - INFO - Epoch [5][1100/1604]	lr: 5.000e-03, eta: 1:57:13, time: 0.445, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0062, loss_cls: 0.1026, acc: 96.5078, loss_bbox: 0.1086, loss: 0.2220
2022-06-20 15:58:28,633 - mmdet - INFO - Epoch [5][1150/1604]	lr: 5.000e-03, eta: 1:56:49, time: 0.465, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0105, loss_cls: 0.0973, acc: 96.8906, loss_bbox: 0.1047, loss: 0.2201
2022-06-20 15:58:48,139 - mmdet - INFO - Epoch [5][1200/1604]	lr: 5.000e-03, eta: 1:56:17, time: 0.390, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0077, loss_cls: 0.0851, acc: 96.6211, loss_bbox: 0.1220, loss: 0.2202
2022-06-20 15:59:09,472 - mmdet - INFO - Epoch [5][1250/1604]	lr: 5.000e-03, eta: 1:55:50, time: 0.427, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0047, loss_cls: 0.0728, acc: 97.7070, loss_bbox: 0.0811, loss: 0.1666
2022-06-20 15:59:33,384 - mmdet - INFO - Epoch [5][1300/1604]	lr: 5.000e-03, eta: 1:55:27, time: 0.478, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0055, loss_cls: 0.1005, acc: 96.4844, loss_bbox: 0.1139, loss: 0.2250
2022-06-20 15:59:58,315 - mmdet - INFO - Epoch [5][1350/1604]	lr: 5.000e-03, eta: 1:55:06, time: 0.499, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0065, loss_cls: 0.0977, acc: 96.5117, loss_bbox: 0.1094, loss: 0.2192
2022-06-20 16:00:17,904 - mmdet - INFO - Epoch [5][1400/1604]	lr: 5.000e-03, eta: 1:54:35, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0051, loss_cls: 0.0874, acc: 96.9570, loss_bbox: 0.1021, loss: 0.2012
2022-06-20 16:00:41,505 - mmdet - INFO - Epoch [5][1450/1604]	lr: 5.000e-03, eta: 1:54:12, time: 0.472, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0062, loss_cls: 0.0934, acc: 96.4805, loss_bbox: 0.1214, loss: 0.2250
2022-06-20 16:01:01,105 - mmdet - INFO - Epoch [5][1500/1604]	lr: 5.000e-03, eta: 1:53:42, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0078, loss_cls: 0.0897, acc: 96.7812, loss_bbox: 0.1205, loss: 0.2237
2022-06-20 16:01:20,748 - mmdet - INFO - Epoch [5][1550/1604]	lr: 5.000e-03, eta: 1:53:11, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0105, loss_cls: 0.0965, acc: 96.4492, loss_bbox: 0.1155, loss: 0.2312
2022-06-20 16:01:46,393 - mmdet - INFO - Epoch [5][1600/1604]	lr: 5.000e-03, eta: 1:52:52, time: 0.513, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0054, loss_cls: 0.0942, acc: 96.6680, loss_bbox: 0.1043, loss: 0.2097
2022-06-20 16:01:48,041 - mmdet - INFO - Saving checkpoint at 5 epochs
2022-06-20 16:03:29,233 - mmdet - INFO - Evaluating bbox...
2022-06-20 16:03:30,252 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.430 | 2_hanfeng | 0.402 | 3_yueyawan | 0.546 |
| 4_shuiban   | 0.295 | 5_youban  | 0.227 | 6_siban    | 0.206 |
| 7_yiwu      | 0.071 | 8_yahen   | 0.080 | 9_zhehen   | 0.167 |
| 10_yaozhe   | 0.325 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 16:03:30,267 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 16:03:30,268 - mmdet - INFO - Epoch(val) [5][688]	bbox_mAP: 0.2750, bbox_mAP_50: 0.6370, bbox_mAP_75: 0.1760, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.1640, bbox_mAP_l: 0.2930, bbox_mAP_copypaste: 0.275 0.637 0.176 0.000 0.164 0.293
2022-06-20 16:03:53,567 - mmdet - INFO - Epoch [6][50/1604]	lr: 5.000e-03, eta: 1:52:23, time: 0.466, data_time: 0.048, memory: 8933, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0095, loss_cls: 0.0920, acc: 96.7344, loss_bbox: 0.1192, loss: 0.2257
2022-06-20 16:04:14,065 - mmdet - INFO - Epoch [6][100/1604]	lr: 5.000e-03, eta: 1:51:54, time: 0.410, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0074, loss_cls: 0.0805, acc: 96.9102, loss_bbox: 0.0957, loss: 0.1870
2022-06-20 16:04:39,655 - mmdet - INFO - Epoch [6][150/1604]	lr: 5.000e-03, eta: 1:51:34, time: 0.512, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0053, loss_cls: 0.0867, acc: 96.8516, loss_bbox: 0.0975, loss: 0.1970
2022-06-20 16:05:11,547 - mmdet - INFO - Epoch [6][200/1604]	lr: 5.000e-03, eta: 1:51:26, time: 0.638, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0054, loss_cls: 0.0887, acc: 96.6992, loss_bbox: 0.1120, loss: 0.2144
2022-06-20 16:05:31,091 - mmdet - INFO - Epoch [6][250/1604]	lr: 5.000e-03, eta: 1:50:55, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0051, loss_cls: 0.0551, acc: 97.9219, loss_bbox: 0.0843, loss: 0.1487
2022-06-20 16:05:53,591 - mmdet - INFO - Epoch [6][300/1604]	lr: 5.000e-03, eta: 1:50:30, time: 0.450, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0059, loss_cls: 0.0835, acc: 96.8008, loss_bbox: 0.1094, loss: 0.2031
2022-06-20 16:06:13,309 - mmdet - INFO - Epoch [6][350/1604]	lr: 5.000e-03, eta: 1:50:01, time: 0.394, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0048, loss_cls: 0.0773, acc: 97.1719, loss_bbox: 0.1063, loss: 0.1919
2022-06-20 16:06:33,329 - mmdet - INFO - Epoch [6][400/1604]	lr: 5.000e-03, eta: 1:49:31, time: 0.400, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0062, loss_cls: 0.1064, acc: 96.4648, loss_bbox: 0.1210, loss: 0.2399
2022-06-20 16:07:04,253 - mmdet - INFO - Epoch [6][450/1604]	lr: 5.000e-03, eta: 1:49:20, time: 0.618, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0036, loss_cls: 0.0629, acc: 97.7031, loss_bbox: 0.0722, loss: 0.1420
2022-06-20 16:07:39,378 - mmdet - INFO - Epoch [6][500/1604]	lr: 5.000e-03, eta: 1:49:16, time: 0.702, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0117, loss_rpn_bbox: 0.0047, loss_cls: 0.0936, acc: 96.3672, loss_bbox: 0.0919, loss: 0.2019
2022-06-20 16:08:00,376 - mmdet - INFO - Epoch [6][550/1604]	lr: 5.000e-03, eta: 1:48:49, time: 0.420, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0057, loss_cls: 0.0927, acc: 97.0664, loss_bbox: 0.0954, loss: 0.1996
2022-06-20 16:08:21,371 - mmdet - INFO - Epoch [6][600/1604]	lr: 5.000e-03, eta: 1:48:21, time: 0.420, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0069, loss_cls: 0.0930, acc: 96.8828, loss_bbox: 0.1067, loss: 0.2111
2022-06-20 16:08:44,377 - mmdet - INFO - Epoch [6][650/1604]	lr: 5.000e-03, eta: 1:47:57, time: 0.460, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0070, loss_cls: 0.0862, acc: 97.0078, loss_bbox: 0.1068, loss: 0.2090
2022-06-20 16:09:06,355 - mmdet - INFO - Epoch [6][700/1604]	lr: 5.000e-03, eta: 1:47:31, time: 0.440, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0069, loss_cls: 0.0873, acc: 97.3008, loss_bbox: 0.1024, loss: 0.2011
2022-06-20 16:09:34,986 - mmdet - INFO - Epoch [6][750/1604]	lr: 5.000e-03, eta: 1:47:15, time: 0.573, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0044, loss_cls: 0.0717, acc: 97.7227, loss_bbox: 0.0967, loss: 0.1793
2022-06-20 16:10:04,361 - mmdet - INFO - Epoch [6][800/1604]	lr: 5.000e-03, eta: 1:47:01, time: 0.587, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0055, loss_cls: 0.0895, acc: 96.8555, loss_bbox: 0.1052, loss: 0.2045
2022-06-20 16:10:25,915 - mmdet - INFO - Epoch [6][850/1604]	lr: 5.000e-03, eta: 1:46:34, time: 0.431, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0072, loss_cls: 0.1083, acc: 95.9609, loss_bbox: 0.1242, loss: 0.2459
2022-06-20 16:10:47,492 - mmdet - INFO - Epoch [6][900/1604]	lr: 5.000e-03, eta: 1:46:08, time: 0.432, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0057, loss_cls: 0.0757, acc: 97.2578, loss_bbox: 0.0972, loss: 0.1826
2022-06-20 16:11:07,742 - mmdet - INFO - Epoch [6][950/1604]	lr: 5.000e-03, eta: 1:45:39, time: 0.405, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0087, loss_cls: 0.0771, acc: 96.9375, loss_bbox: 0.1112, loss: 0.2015
2022-06-20 16:11:32,743 - mmdet - INFO - Epoch [6][1000/1604]	lr: 5.000e-03, eta: 1:45:18, time: 0.500, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0058, loss_cls: 0.0697, acc: 97.3438, loss_bbox: 0.0858, loss: 0.1647
2022-06-20 16:12:03,345 - mmdet - INFO - Epoch [6][1050/1604]	lr: 5.000e-03, eta: 1:45:05, time: 0.612, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0112, loss_cls: 0.0768, acc: 97.3633, loss_bbox: 0.0886, loss: 0.1841
2022-06-20 16:12:27,918 - mmdet - INFO - Epoch [6][1100/1604]	lr: 5.000e-03, eta: 1:44:43, time: 0.491, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0090, loss_cls: 0.0820, acc: 97.5508, loss_bbox: 0.0853, loss: 0.1838
2022-06-20 16:12:47,344 - mmdet - INFO - Epoch [6][1150/1604]	lr: 5.000e-03, eta: 1:44:13, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0069, loss_cls: 0.1008, acc: 96.8203, loss_bbox: 0.1103, loss: 0.2255
2022-06-20 16:13:06,662 - mmdet - INFO - Epoch [6][1200/1604]	lr: 5.000e-03, eta: 1:43:44, time: 0.386, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0071, loss_cls: 0.0861, acc: 96.9375, loss_bbox: 0.1170, loss: 0.2144
2022-06-20 16:13:27,294 - mmdet - INFO - Epoch [6][1250/1604]	lr: 5.000e-03, eta: 1:43:16, time: 0.413, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0071, loss_cls: 0.0957, acc: 96.5195, loss_bbox: 0.1199, loss: 0.2311
2022-06-20 16:13:51,643 - mmdet - INFO - Epoch [6][1300/1604]	lr: 5.000e-03, eta: 1:42:54, time: 0.487, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0070, loss_cls: 0.0951, acc: 96.4102, loss_bbox: 0.1128, loss: 0.2192
2022-06-20 16:14:14,615 - mmdet - INFO - Epoch [6][1350/1604]	lr: 5.000e-03, eta: 1:42:30, time: 0.459, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0054, loss_cls: 0.0843, acc: 97.1445, loss_bbox: 0.0979, loss: 0.1903
2022-06-20 16:14:36,543 - mmdet - INFO - Epoch [6][1400/1604]	lr: 5.000e-03, eta: 1:42:04, time: 0.439, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0063, loss_cls: 0.0932, acc: 96.3477, loss_bbox: 0.1205, loss: 0.2251
2022-06-20 16:14:57,803 - mmdet - INFO - Epoch [6][1450/1604]	lr: 5.000e-03, eta: 1:41:37, time: 0.425, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0074, loss_cls: 0.0790, acc: 97.1055, loss_bbox: 0.1062, loss: 0.1979
2022-06-20 16:15:21,250 - mmdet - INFO - Epoch [6][1500/1604]	lr: 5.000e-03, eta: 1:41:14, time: 0.469, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0056, loss_cls: 0.1033, acc: 96.5273, loss_bbox: 0.1070, loss: 0.2208
2022-06-20 16:15:51,840 - mmdet - INFO - Epoch [6][1550/1604]	lr: 5.000e-03, eta: 1:41:00, time: 0.612, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0051, loss_cls: 0.0827, acc: 97.1211, loss_bbox: 0.1028, loss: 0.1953
2022-06-20 16:16:18,248 - mmdet - INFO - Epoch [6][1600/1604]	lr: 5.000e-03, eta: 1:40:40, time: 0.528, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0064, loss_cls: 0.1005, acc: 96.3008, loss_bbox: 0.1315, loss: 0.2442
2022-06-20 16:16:23,206 - mmdet - INFO - Saving checkpoint at 6 epochs
2022-06-20 16:18:05,275 - mmdet - INFO - Evaluating bbox...
2022-06-20 16:18:06,170 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.452 | 2_hanfeng | 0.212 | 3_yueyawan | 0.533 |
| 4_shuiban   | 0.355 | 5_youban  | 0.179 | 6_siban    | 0.185 |
| 7_yiwu      | 0.080 | 8_yahen   | 0.062 | 9_zhehen   | 0.114 |
| 10_yaozhe   | 0.289 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 16:18:06,195 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 16:18:06,195 - mmdet - INFO - Epoch(val) [6][688]	bbox_mAP: 0.2460, bbox_mAP_50: 0.5690, bbox_mAP_75: 0.1740, bbox_mAP_s: 0.1000, bbox_mAP_m: 0.1620, bbox_mAP_l: 0.2420, bbox_mAP_copypaste: 0.246 0.569 0.174 0.100 0.162 0.242
2022-06-20 16:18:37,406 - mmdet - INFO - Epoch [7][50/1604]	lr: 5.000e-03, eta: 1:40:23, time: 0.624, data_time: 0.051, memory: 8933, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0062, loss_cls: 0.0870, acc: 96.7070, loss_bbox: 0.1086, loss: 0.2055
2022-06-20 16:18:57,783 - mmdet - INFO - Epoch [7][100/1604]	lr: 5.000e-03, eta: 1:39:55, time: 0.408, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0058, loss_cls: 0.0833, acc: 97.1016, loss_bbox: 0.0991, loss: 0.1944
2022-06-20 16:19:19,218 - mmdet - INFO - Epoch [7][150/1604]	lr: 5.000e-03, eta: 1:39:29, time: 0.429, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0064, loss_cls: 0.0973, acc: 96.7422, loss_bbox: 0.0990, loss: 0.2075
2022-06-20 16:19:43,405 - mmdet - INFO - Epoch [7][200/1604]	lr: 5.000e-03, eta: 1:39:06, time: 0.484, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0084, loss_cls: 0.0899, acc: 96.7539, loss_bbox: 0.1072, loss: 0.2097
2022-06-20 16:20:03,869 - mmdet - INFO - Epoch [7][250/1604]	lr: 5.000e-03, eta: 1:38:38, time: 0.409, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0058, loss_cls: 0.0759, acc: 97.1758, loss_bbox: 0.0967, loss: 0.1820
2022-06-20 16:20:23,469 - mmdet - INFO - Epoch [7][300/1604]	lr: 5.000e-03, eta: 1:38:10, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0058, loss_cls: 0.0718, acc: 97.1016, loss_bbox: 0.0989, loss: 0.1789
2022-06-20 16:20:54,615 - mmdet - INFO - Epoch [7][350/1604]	lr: 5.000e-03, eta: 1:37:56, time: 0.623, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0082, loss_cls: 0.0839, acc: 96.8516, loss_bbox: 0.0987, loss: 0.1952
2022-06-20 16:21:16,102 - mmdet - INFO - Epoch [7][400/1604]	lr: 5.000e-03, eta: 1:37:30, time: 0.430, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0091, loss_cls: 0.0901, acc: 96.7969, loss_bbox: 0.1047, loss: 0.2130
2022-06-20 16:21:38,236 - mmdet - INFO - Epoch [7][450/1604]	lr: 5.000e-03, eta: 1:37:05, time: 0.443, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0076, loss_cls: 0.0936, acc: 96.8203, loss_bbox: 0.1128, loss: 0.2188
2022-06-20 16:21:57,913 - mmdet - INFO - Epoch [7][500/1604]	lr: 5.000e-03, eta: 1:36:36, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0048, loss_cls: 0.0809, acc: 97.0352, loss_bbox: 0.1061, loss: 0.1946
2022-06-20 16:22:17,403 - mmdet - INFO - Epoch [7][550/1604]	lr: 5.000e-03, eta: 1:36:08, time: 0.390, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0080, loss_cls: 0.0786, acc: 97.1602, loss_bbox: 0.0942, loss: 0.1851
2022-06-20 16:22:37,155 - mmdet - INFO - Epoch [7][600/1604]	lr: 5.000e-03, eta: 1:35:40, time: 0.395, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0071, loss_cls: 0.0793, acc: 97.1953, loss_bbox: 0.1108, loss: 0.2012
2022-06-20 16:23:00,949 - mmdet - INFO - Epoch [7][650/1604]	lr: 5.000e-03, eta: 1:35:17, time: 0.476, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0076, loss_cls: 0.0789, acc: 97.1875, loss_bbox: 0.0971, loss: 0.1885
2022-06-20 16:23:22,604 - mmdet - INFO - Epoch [7][700/1604]	lr: 5.000e-03, eta: 1:34:52, time: 0.433, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0075, loss_cls: 0.0901, acc: 96.7148, loss_bbox: 0.1105, loss: 0.2139
2022-06-20 16:23:45,760 - mmdet - INFO - Epoch [7][750/1604]	lr: 5.000e-03, eta: 1:34:28, time: 0.463, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0084, loss_cls: 0.0798, acc: 96.9219, loss_bbox: 0.1037, loss: 0.1960
2022-06-20 16:24:12,933 - mmdet - INFO - Epoch [7][800/1604]	lr: 5.000e-03, eta: 1:34:09, time: 0.543, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0074, loss_cls: 0.0827, acc: 96.7500, loss_bbox: 0.1097, loss: 0.2035
2022-06-20 16:24:32,747 - mmdet - INFO - Epoch [7][850/1604]	lr: 5.000e-03, eta: 1:33:41, time: 0.396, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0051, loss_cls: 0.0841, acc: 97.1016, loss_bbox: 0.1079, loss: 0.2025
2022-06-20 16:24:52,423 - mmdet - INFO - Epoch [7][900/1604]	lr: 5.000e-03, eta: 1:33:13, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0067, loss_cls: 0.0824, acc: 97.2969, loss_bbox: 0.1007, loss: 0.1960
2022-06-20 16:25:14,344 - mmdet - INFO - Epoch [7][950/1604]	lr: 5.000e-03, eta: 1:32:48, time: 0.438, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0059, loss_cls: 0.0850, acc: 97.3164, loss_bbox: 0.0966, loss: 0.1943
2022-06-20 16:25:41,875 - mmdet - INFO - Epoch [7][1000/1604]	lr: 5.000e-03, eta: 1:32:29, time: 0.551, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0055, loss_cls: 0.0799, acc: 97.0078, loss_bbox: 0.1110, loss: 0.2011
2022-06-20 16:26:11,016 - mmdet - INFO - Epoch [7][1050/1604]	lr: 5.000e-03, eta: 1:32:12, time: 0.583, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0046, loss_cls: 0.0934, acc: 96.6250, loss_bbox: 0.1184, loss: 0.2205
2022-06-20 16:26:41,472 - mmdet - INFO - Epoch [7][1100/1604]	lr: 5.000e-03, eta: 1:31:56, time: 0.609, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0056, loss_cls: 0.0749, acc: 97.1758, loss_bbox: 0.0996, loss: 0.1843
2022-06-20 16:27:10,908 - mmdet - INFO - Epoch [7][1150/1604]	lr: 5.000e-03, eta: 1:31:39, time: 0.589, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0056, loss_cls: 0.0872, acc: 96.6250, loss_bbox: 0.1161, loss: 0.2125
2022-06-20 16:27:38,676 - mmdet - INFO - Epoch [7][1200/1604]	lr: 5.000e-03, eta: 1:31:20, time: 0.555, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0047, loss_cls: 0.0847, acc: 96.6953, loss_bbox: 0.1103, loss: 0.2029
2022-06-20 16:28:09,418 - mmdet - INFO - Epoch [7][1250/1604]	lr: 5.000e-03, eta: 1:31:04, time: 0.615, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0045, loss_cls: 0.0784, acc: 97.2812, loss_bbox: 0.0857, loss: 0.1727
2022-06-20 16:28:35,664 - mmdet - INFO - Epoch [7][1300/1604]	lr: 5.000e-03, eta: 1:30:43, time: 0.525, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0053, loss_cls: 0.0936, acc: 96.7969, loss_bbox: 0.1044, loss: 0.2110
2022-06-20 16:29:00,385 - mmdet - INFO - Epoch [7][1350/1604]	lr: 5.000e-03, eta: 1:30:21, time: 0.495, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0050, loss_cls: 0.0881, acc: 96.5312, loss_bbox: 0.1179, loss: 0.2182
2022-06-20 16:29:25,951 - mmdet - INFO - Epoch [7][1400/1604]	lr: 5.000e-03, eta: 1:29:59, time: 0.511, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0044, loss_cls: 0.0734, acc: 97.5000, loss_bbox: 0.0962, loss: 0.1784
2022-06-20 16:29:53,354 - mmdet - INFO - Epoch [7][1450/1604]	lr: 5.000e-03, eta: 1:29:40, time: 0.548, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0072, loss_cls: 0.0719, acc: 97.4453, loss_bbox: 0.0906, loss: 0.1729
2022-06-20 16:30:19,935 - mmdet - INFO - Epoch [7][1500/1604]	lr: 5.000e-03, eta: 1:29:19, time: 0.532, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0088, loss_cls: 0.0851, acc: 97.1875, loss_bbox: 0.0952, loss: 0.1955
2022-06-20 16:30:43,868 - mmdet - INFO - Epoch [7][1550/1604]	lr: 5.000e-03, eta: 1:28:56, time: 0.479, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0077, loss_cls: 0.0978, acc: 96.3750, loss_bbox: 0.1323, loss: 0.2429
2022-06-20 16:31:11,481 - mmdet - INFO - Epoch [7][1600/1604]	lr: 5.000e-03, eta: 1:28:36, time: 0.552, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0066, loss_cls: 0.0764, acc: 97.0781, loss_bbox: 0.0931, loss: 0.1796
2022-06-20 16:31:13,602 - mmdet - INFO - Saving checkpoint at 7 epochs
2022-06-20 16:33:22,320 - mmdet - INFO - Evaluating bbox...
2022-06-20 16:33:23,329 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.471 | 2_hanfeng | 0.466 | 3_yueyawan | 0.559 |
| 4_shuiban   | 0.390 | 5_youban  | 0.221 | 6_siban    | 0.240 |
| 7_yiwu      | 0.084 | 8_yahen   | 0.085 | 9_zhehen   | 0.124 |
| 10_yaozhe   | 0.216 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 16:33:23,346 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 16:33:23,347 - mmdet - INFO - Epoch(val) [7][688]	bbox_mAP: 0.2860, bbox_mAP_50: 0.6250, bbox_mAP_75: 0.2170, bbox_mAP_s: 0.1340, bbox_mAP_m: 0.1580, bbox_mAP_l: 0.2780, bbox_mAP_copypaste: 0.286 0.625 0.217 0.134 0.158 0.278
2022-06-20 16:33:53,334 - mmdet - INFO - Epoch [8][50/1604]	lr: 5.000e-03, eta: 1:28:15, time: 0.599, data_time: 0.052, memory: 8933, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0060, loss_cls: 0.0747, acc: 97.2383, loss_bbox: 0.0812, loss: 0.1654
2022-06-20 16:34:22,505 - mmdet - INFO - Epoch [8][100/1604]	lr: 5.000e-03, eta: 1:27:56, time: 0.583, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0072, loss_cls: 0.0985, acc: 96.3711, loss_bbox: 0.1225, loss: 0.2321
2022-06-20 16:34:50,992 - mmdet - INFO - Epoch [8][150/1604]	lr: 5.000e-03, eta: 1:27:37, time: 0.570, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0053, loss_cls: 0.0810, acc: 96.8164, loss_bbox: 0.1067, loss: 0.1984
2022-06-20 16:35:22,425 - mmdet - INFO - Epoch [8][200/1604]	lr: 5.000e-03, eta: 1:27:21, time: 0.629, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0061, loss_cls: 0.0657, acc: 97.5352, loss_bbox: 0.0892, loss: 0.1627
2022-06-20 16:35:52,889 - mmdet - INFO - Epoch [8][250/1604]	lr: 5.000e-03, eta: 1:27:04, time: 0.609, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0042, loss_cls: 0.0796, acc: 97.2812, loss_bbox: 0.0944, loss: 0.1809
2022-06-20 16:36:21,259 - mmdet - INFO - Epoch [8][300/1604]	lr: 5.000e-03, eta: 1:26:44, time: 0.567, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0067, loss_cls: 0.0873, acc: 96.6953, loss_bbox: 0.1194, loss: 0.2190
2022-06-20 16:36:53,337 - mmdet - INFO - Epoch [8][350/1604]	lr: 5.000e-03, eta: 1:26:28, time: 0.642, data_time: 0.012, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0064, loss_cls: 0.0652, acc: 97.6367, loss_bbox: 0.0850, loss: 0.1596
2022-06-20 16:37:21,543 - mmdet - INFO - Epoch [8][400/1604]	lr: 5.000e-03, eta: 1:26:08, time: 0.564, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0053, loss_cls: 0.0679, acc: 97.3477, loss_bbox: 0.0941, loss: 0.1703
2022-06-20 16:37:47,705 - mmdet - INFO - Epoch [8][450/1604]	lr: 5.000e-03, eta: 1:25:47, time: 0.523, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0070, loss_cls: 0.0642, acc: 97.6758, loss_bbox: 0.0928, loss: 0.1680
2022-06-20 16:38:10,689 - mmdet - INFO - Epoch [8][500/1604]	lr: 5.000e-03, eta: 1:25:22, time: 0.460, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0089, loss_cls: 0.0632, acc: 97.4570, loss_bbox: 0.0922, loss: 0.1689
2022-06-20 16:38:37,247 - mmdet - INFO - Epoch [8][550/1604]	lr: 5.000e-03, eta: 1:25:01, time: 0.531, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0083, loss_cls: 0.1090, acc: 95.8828, loss_bbox: 0.1336, loss: 0.2577
2022-06-20 16:39:02,521 - mmdet - INFO - Epoch [8][600/1604]	lr: 5.000e-03, eta: 1:24:38, time: 0.505, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0046, loss_cls: 0.0694, acc: 97.4570, loss_bbox: 0.0961, loss: 0.1737
2022-06-20 16:39:25,596 - mmdet - INFO - Epoch [8][650/1604]	lr: 5.000e-03, eta: 1:24:13, time: 0.461, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0058, loss_cls: 0.0857, acc: 96.4688, loss_bbox: 0.1174, loss: 0.2130
2022-06-20 16:39:55,656 - mmdet - INFO - Epoch [8][700/1604]	lr: 5.000e-03, eta: 1:23:55, time: 0.601, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0064, loss_cls: 0.0519, acc: 97.9922, loss_bbox: 0.0841, loss: 0.1441
2022-06-20 16:40:20,776 - mmdet - INFO - Epoch [8][750/1604]	lr: 5.000e-03, eta: 1:23:32, time: 0.502, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0057, loss_cls: 0.0714, acc: 97.4453, loss_bbox: 0.0971, loss: 0.1788
2022-06-20 16:40:46,949 - mmdet - INFO - Epoch [8][800/1604]	lr: 5.000e-03, eta: 1:23:10, time: 0.523, data_time: 0.025, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0054, loss_cls: 0.0721, acc: 97.1055, loss_bbox: 0.1061, loss: 0.1878
2022-06-20 16:41:12,148 - mmdet - INFO - Epoch [8][850/1604]	lr: 5.000e-03, eta: 1:22:47, time: 0.504, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0045, loss_cls: 0.0570, acc: 98.0195, loss_bbox: 0.0790, loss: 0.1429
2022-06-20 16:41:41,771 - mmdet - INFO - Epoch [8][900/1604]	lr: 5.000e-03, eta: 1:22:28, time: 0.592, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0044, loss_cls: 0.0731, acc: 97.1055, loss_bbox: 0.1021, loss: 0.1838
2022-06-20 16:42:11,567 - mmdet - INFO - Epoch [8][950/1604]	lr: 5.000e-03, eta: 1:22:09, time: 0.596, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0056, loss_cls: 0.0792, acc: 96.9570, loss_bbox: 0.1094, loss: 0.1996
2022-06-20 16:42:44,697 - mmdet - INFO - Epoch [8][1000/1604]	lr: 5.000e-03, eta: 1:21:53, time: 0.662, data_time: 0.028, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0054, loss_cls: 0.0739, acc: 97.0586, loss_bbox: 0.1007, loss: 0.1831
2022-06-20 16:43:16,409 - mmdet - INFO - Epoch [8][1050/1604]	lr: 5.000e-03, eta: 1:21:35, time: 0.634, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0040, loss_cls: 0.0753, acc: 97.5195, loss_bbox: 0.0857, loss: 0.1698
2022-06-20 16:43:49,407 - mmdet - INFO - Epoch [8][1100/1604]	lr: 5.000e-03, eta: 1:21:18, time: 0.660, data_time: 0.017, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0037, loss_cls: 0.0638, acc: 97.4844, loss_bbox: 0.0827, loss: 0.1525
2022-06-20 16:44:19,064 - mmdet - INFO - Epoch [8][1150/1604]	lr: 5.000e-03, eta: 1:20:59, time: 0.593, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0091, loss_cls: 0.0803, acc: 96.8047, loss_bbox: 0.1175, loss: 0.2117
2022-06-20 16:44:46,372 - mmdet - INFO - Epoch [8][1200/1604]	lr: 5.000e-03, eta: 1:20:37, time: 0.546, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0031, loss_cls: 0.0712, acc: 97.2773, loss_bbox: 0.1036, loss: 0.1810
2022-06-20 16:45:17,394 - mmdet - INFO - Epoch [8][1250/1604]	lr: 5.000e-03, eta: 1:20:19, time: 0.620, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0053, loss_cls: 0.0740, acc: 97.2383, loss_bbox: 0.1037, loss: 0.1862
2022-06-20 16:45:43,891 - mmdet - INFO - Epoch [8][1300/1604]	lr: 5.000e-03, eta: 1:19:56, time: 0.530, data_time: 0.016, memory: 8933, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0052, loss_cls: 0.0787, acc: 97.1758, loss_bbox: 0.1050, loss: 0.1932
2022-06-20 16:46:17,490 - mmdet - INFO - Epoch [8][1350/1604]	lr: 5.000e-03, eta: 1:19:40, time: 0.672, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0080, loss_cls: 0.1176, acc: 96.2656, loss_bbox: 0.1200, loss: 0.2502
2022-06-20 16:46:52,948 - mmdet - INFO - Epoch [8][1400/1604]	lr: 5.000e-03, eta: 1:19:24, time: 0.709, data_time: 0.025, memory: 8933, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0053, loss_cls: 0.0859, acc: 96.9531, loss_bbox: 0.1037, loss: 0.2016
2022-06-20 16:47:24,497 - mmdet - INFO - Epoch [8][1450/1604]	lr: 5.000e-03, eta: 1:19:06, time: 0.631, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0049, loss_cls: 0.0795, acc: 96.8750, loss_bbox: 0.1063, loss: 0.1964
2022-06-20 16:47:59,723 - mmdet - INFO - Epoch [8][1500/1604]	lr: 5.000e-03, eta: 1:18:50, time: 0.705, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0078, loss_cls: 0.0836, acc: 96.9648, loss_bbox: 0.1072, loss: 0.2053
2022-06-20 16:48:37,370 - mmdet - INFO - Epoch [8][1550/1604]	lr: 5.000e-03, eta: 1:18:35, time: 0.753, data_time: 0.011, memory: 8933, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0069, loss_cls: 0.0776, acc: 97.4805, loss_bbox: 0.0883, loss: 0.1782
2022-06-20 16:49:08,951 - mmdet - INFO - Epoch [8][1600/1604]	lr: 5.000e-03, eta: 1:18:17, time: 0.632, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0098, loss_cls: 0.0834, acc: 96.6992, loss_bbox: 0.1109, loss: 0.2107
2022-06-20 16:49:11,131 - mmdet - INFO - Saving checkpoint at 8 epochs
2022-06-20 16:51:19,753 - mmdet - INFO - Evaluating bbox...
2022-06-20 16:51:21,196 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.517 | 2_hanfeng | 0.371 | 3_yueyawan | 0.451 |
| 4_shuiban   | 0.392 | 5_youban  | 0.210 | 6_siban    | 0.234 |
| 7_yiwu      | 0.114 | 8_yahen   | 0.173 | 9_zhehen   | 0.070 |
| 10_yaozhe   | 0.393 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 16:51:21,245 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 16:51:21,245 - mmdet - INFO - Epoch(val) [8][688]	bbox_mAP: 0.2930, bbox_mAP_50: 0.6720, bbox_mAP_75: 0.2020, bbox_mAP_s: 0.0630, bbox_mAP_m: 0.1730, bbox_mAP_l: 0.2980, bbox_mAP_copypaste: 0.293 0.672 0.202 0.063 0.173 0.298
2022-06-20 16:51:57,675 - mmdet - INFO - Epoch [9][50/1604]	lr: 5.000e-04, eta: 1:17:58, time: 0.728, data_time: 0.052, memory: 8933, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0066, loss_cls: 0.0611, acc: 97.7109, loss_bbox: 0.0929, loss: 0.1651
2022-06-20 16:52:27,337 - mmdet - INFO - Epoch [9][100/1604]	lr: 5.000e-04, eta: 1:17:37, time: 0.593, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0079, loss_cls: 0.0844, acc: 96.7383, loss_bbox: 0.1186, loss: 0.2159
2022-06-20 16:52:56,307 - mmdet - INFO - Epoch [9][150/1604]	lr: 5.000e-04, eta: 1:17:16, time: 0.579, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0060, loss_cls: 0.0687, acc: 97.2852, loss_bbox: 0.1065, loss: 0.1843
2022-06-20 16:53:29,214 - mmdet - INFO - Epoch [9][200/1604]	lr: 5.000e-04, eta: 1:16:58, time: 0.658, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0047, loss_cls: 0.0748, acc: 96.9844, loss_bbox: 0.1036, loss: 0.1861
2022-06-20 16:53:54,273 - mmdet - INFO - Epoch [9][250/1604]	lr: 5.000e-04, eta: 1:16:33, time: 0.501, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0033, loss_cls: 0.0637, acc: 97.4531, loss_bbox: 0.0909, loss: 0.1625
2022-06-20 16:54:14,255 - mmdet - INFO - Epoch [9][300/1604]	lr: 5.000e-04, eta: 1:16:06, time: 0.400, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0040, loss_cls: 0.0658, acc: 97.3828, loss_bbox: 0.0983, loss: 0.1711
2022-06-20 16:54:36,163 - mmdet - INFO - Epoch [9][350/1604]	lr: 5.000e-04, eta: 1:15:39, time: 0.438, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0041, loss_cls: 0.0666, acc: 97.5234, loss_bbox: 0.0965, loss: 0.1717
2022-06-20 16:54:58,833 - mmdet - INFO - Epoch [9][400/1604]	lr: 5.000e-04, eta: 1:15:14, time: 0.453, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0044, loss_cls: 0.0742, acc: 97.3906, loss_bbox: 0.1000, loss: 0.1823
2022-06-20 16:55:21,462 - mmdet - INFO - Epoch [9][450/1604]	lr: 5.000e-04, eta: 1:14:48, time: 0.453, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0034, loss_cls: 0.0643, acc: 97.3711, loss_bbox: 0.0878, loss: 0.1586
2022-06-20 16:55:46,122 - mmdet - INFO - Epoch [9][500/1604]	lr: 5.000e-04, eta: 1:14:24, time: 0.493, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0046, loss_cls: 0.0479, acc: 98.0859, loss_bbox: 0.0707, loss: 0.1264
2022-06-20 16:56:05,700 - mmdet - INFO - Epoch [9][550/1604]	lr: 5.000e-04, eta: 1:13:56, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0036, loss_cls: 0.0588, acc: 97.5273, loss_bbox: 0.0920, loss: 0.1584
2022-06-20 16:56:25,610 - mmdet - INFO - Epoch [9][600/1604]	lr: 5.000e-04, eta: 1:13:28, time: 0.398, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0062, loss_cls: 0.0896, acc: 96.2656, loss_bbox: 0.1258, loss: 0.2273
2022-06-20 16:56:45,185 - mmdet - INFO - Epoch [9][650/1604]	lr: 5.000e-04, eta: 1:13:01, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0050, loss_cls: 0.0796, acc: 97.1328, loss_bbox: 0.0921, loss: 0.1805
2022-06-20 16:57:04,711 - mmdet - INFO - Epoch [9][700/1604]	lr: 5.000e-04, eta: 1:12:33, time: 0.391, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0052, loss_cls: 0.0617, acc: 97.5547, loss_bbox: 0.0866, loss: 0.1560
2022-06-20 16:57:27,367 - mmdet - INFO - Epoch [9][750/1604]	lr: 5.000e-04, eta: 1:12:08, time: 0.453, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0063, loss_cls: 0.0810, acc: 97.1875, loss_bbox: 0.0982, loss: 0.1895
2022-06-20 16:57:49,737 - mmdet - INFO - Epoch [9][800/1604]	lr: 5.000e-04, eta: 1:11:42, time: 0.447, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0037, loss_cls: 0.0525, acc: 97.8906, loss_bbox: 0.0726, loss: 0.1308
2022-06-20 16:58:09,207 - mmdet - INFO - Epoch [9][850/1604]	lr: 5.000e-04, eta: 1:11:14, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0050, loss_cls: 0.0625, acc: 97.4023, loss_bbox: 0.0972, loss: 0.1673
2022-06-20 16:58:29,459 - mmdet - INFO - Epoch [9][900/1604]	lr: 5.000e-04, eta: 1:10:47, time: 0.405, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, loss_cls: 0.0604, acc: 97.5859, loss_bbox: 0.0812, loss: 0.1491
2022-06-20 16:58:49,027 - mmdet - INFO - Epoch [9][950/1604]	lr: 5.000e-04, eta: 1:10:20, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0063, loss_cls: 0.0633, acc: 97.4922, loss_bbox: 0.0960, loss: 0.1686
2022-06-20 16:59:08,510 - mmdet - INFO - Epoch [9][1000/1604]	lr: 5.000e-04, eta: 1:09:53, time: 0.390, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0043, loss_cls: 0.0586, acc: 97.8750, loss_bbox: 0.0849, loss: 0.1512
2022-06-20 16:59:35,692 - mmdet - INFO - Epoch [9][1050/1604]	lr: 5.000e-04, eta: 1:09:30, time: 0.544, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0031, loss_cls: 0.0571, acc: 97.6094, loss_bbox: 0.0846, loss: 0.1467
2022-06-20 17:00:12,651 - mmdet - INFO - Epoch [9][1100/1604]	lr: 5.000e-04, eta: 1:09:14, time: 0.739, data_time: 0.011, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0064, loss_cls: 0.0716, acc: 97.1680, loss_bbox: 0.1046, loss: 0.1847
2022-06-20 17:00:34,442 - mmdet - INFO - Epoch [9][1150/1604]	lr: 5.000e-04, eta: 1:08:48, time: 0.436, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0037, loss_cls: 0.0609, acc: 97.6836, loss_bbox: 0.0939, loss: 0.1608
2022-06-20 17:00:53,599 - mmdet - INFO - Epoch [9][1200/1604]	lr: 5.000e-04, eta: 1:08:20, time: 0.383, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0058, loss_cls: 0.0449, acc: 98.1836, loss_bbox: 0.0654, loss: 0.1195
2022-06-20 17:01:17,259 - mmdet - INFO - Epoch [9][1250/1604]	lr: 5.000e-04, eta: 1:07:55, time: 0.473, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0045, loss_cls: 0.0525, acc: 97.8750, loss_bbox: 0.0817, loss: 0.1416
2022-06-20 17:01:43,170 - mmdet - INFO - Epoch [9][1300/1604]	lr: 5.000e-04, eta: 1:07:32, time: 0.518, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0026, loss_cls: 0.0522, acc: 97.9336, loss_bbox: 0.0900, loss: 0.1466
2022-06-20 17:02:02,553 - mmdet - INFO - Epoch [9][1350/1604]	lr: 5.000e-04, eta: 1:07:05, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0045, loss_cls: 0.0669, acc: 97.2578, loss_bbox: 0.1082, loss: 0.1826
2022-06-20 17:02:21,991 - mmdet - INFO - Epoch [9][1400/1604]	lr: 5.000e-04, eta: 1:06:38, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0048, loss_cls: 0.0622, acc: 97.5664, loss_bbox: 0.0874, loss: 0.1570
2022-06-20 17:02:50,078 - mmdet - INFO - Epoch [9][1450/1604]	lr: 5.000e-04, eta: 1:06:15, time: 0.562, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0028, loss_cls: 0.0534, acc: 97.8008, loss_bbox: 0.0791, loss: 0.1370
2022-06-20 17:03:22,423 - mmdet - INFO - Epoch [9][1500/1604]	lr: 5.000e-04, eta: 1:05:56, time: 0.647, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0029, loss_cls: 0.0492, acc: 97.9023, loss_bbox: 0.0786, loss: 0.1326
2022-06-20 17:03:49,181 - mmdet - INFO - Epoch [9][1550/1604]	lr: 5.000e-04, eta: 1:05:33, time: 0.535, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0038, loss_cls: 0.0712, acc: 97.4258, loss_bbox: 0.0963, loss: 0.1743
2022-06-20 17:04:09,232 - mmdet - INFO - Epoch [9][1600/1604]	lr: 5.000e-04, eta: 1:05:06, time: 0.401, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0031, loss_cls: 0.0568, acc: 97.6328, loss_bbox: 0.0980, loss: 0.1629
2022-06-20 17:04:10,888 - mmdet - INFO - Saving checkpoint at 9 epochs
2022-06-20 17:05:42,995 - mmdet - INFO - Evaluating bbox...
2022-06-20 17:05:43,740 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.526 | 2_hanfeng | 0.463 | 3_yueyawan | 0.637 |
| 4_shuiban   | 0.427 | 5_youban  | 0.233 | 6_siban    | 0.271 |
| 7_yiwu      | 0.140 | 8_yahen   | 0.163 | 9_zhehen   | 0.164 |
| 10_yaozhe   | 0.405 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 17:05:43,751 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 17:05:43,752 - mmdet - INFO - Epoch(val) [9][688]	bbox_mAP: 0.3430, bbox_mAP_50: 0.7210, bbox_mAP_75: 0.2830, bbox_mAP_s: 0.0600, bbox_mAP_m: 0.1870, bbox_mAP_l: 0.3480, bbox_mAP_copypaste: 0.343 0.721 0.283 0.060 0.187 0.348
2022-06-20 17:06:07,671 - mmdet - INFO - Epoch [10][50/1604]	lr: 5.000e-04, eta: 1:04:38, time: 0.478, data_time: 0.048, memory: 8933, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0044, loss_cls: 0.0614, acc: 97.4492, loss_bbox: 0.0969, loss: 0.1654
2022-06-20 17:06:33,503 - mmdet - INFO - Epoch [10][100/1604]	lr: 5.000e-04, eta: 1:04:15, time: 0.517, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0038, loss_cls: 0.0650, acc: 97.5039, loss_bbox: 0.0952, loss: 0.1675
2022-06-20 17:06:54,744 - mmdet - INFO - Epoch [10][150/1604]	lr: 5.000e-04, eta: 1:03:49, time: 0.425, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0041, loss_cls: 0.0636, acc: 97.3203, loss_bbox: 0.1020, loss: 0.1720
2022-06-20 17:07:16,982 - mmdet - INFO - Epoch [10][200/1604]	lr: 5.000e-04, eta: 1:03:23, time: 0.445, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0028, loss_cls: 0.0544, acc: 97.8281, loss_bbox: 0.0758, loss: 0.1356
2022-06-20 17:07:38,706 - mmdet - INFO - Epoch [10][250/1604]	lr: 5.000e-04, eta: 1:02:58, time: 0.434, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0039, loss_cls: 0.0603, acc: 97.5859, loss_bbox: 0.0887, loss: 0.1549
2022-06-20 17:08:05,362 - mmdet - INFO - Epoch [10][300/1604]	lr: 5.000e-04, eta: 1:02:35, time: 0.533, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0035, loss_cls: 0.0570, acc: 97.4531, loss_bbox: 0.0905, loss: 0.1524
2022-06-20 17:08:28,960 - mmdet - INFO - Epoch [10][350/1604]	lr: 5.000e-04, eta: 1:02:10, time: 0.472, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0031, loss_cls: 0.0567, acc: 97.7930, loss_bbox: 0.0831, loss: 0.1453
2022-06-20 17:08:56,842 - mmdet - INFO - Epoch [10][400/1604]	lr: 5.000e-04, eta: 1:01:47, time: 0.558, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0038, loss_cls: 0.0600, acc: 97.3828, loss_bbox: 0.0945, loss: 0.1608
2022-06-20 17:09:19,436 - mmdet - INFO - Epoch [10][450/1604]	lr: 5.000e-04, eta: 1:01:22, time: 0.452, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0045, loss_cls: 0.0812, acc: 97.1328, loss_bbox: 0.0987, loss: 0.1873
2022-06-20 17:09:43,023 - mmdet - INFO - Epoch [10][500/1604]	lr: 5.000e-04, eta: 1:00:57, time: 0.472, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0041, loss_cls: 0.0483, acc: 98.0391, loss_bbox: 0.0746, loss: 0.1286
2022-06-20 17:10:05,934 - mmdet - INFO - Epoch [10][550/1604]	lr: 5.000e-04, eta: 1:00:32, time: 0.458, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0034, loss_cls: 0.0499, acc: 97.8594, loss_bbox: 0.0797, loss: 0.1354
2022-06-20 17:10:27,103 - mmdet - INFO - Epoch [10][600/1604]	lr: 5.000e-04, eta: 1:00:07, time: 0.423, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0024, loss_cls: 0.0539, acc: 97.7656, loss_bbox: 0.0761, loss: 0.1338
2022-06-20 17:10:47,656 - mmdet - INFO - Epoch [10][650/1604]	lr: 5.000e-04, eta: 0:59:40, time: 0.411, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0037, loss_cls: 0.0548, acc: 97.6445, loss_bbox: 0.0857, loss: 0.1461
2022-06-20 17:11:07,790 - mmdet - INFO - Epoch [10][700/1604]	lr: 5.000e-04, eta: 0:59:14, time: 0.403, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0045, loss_cls: 0.0557, acc: 97.6836, loss_bbox: 0.0933, loss: 0.1566
2022-06-20 17:11:34,105 - mmdet - INFO - Epoch [10][750/1604]	lr: 5.000e-04, eta: 0:58:51, time: 0.526, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0032, loss_cls: 0.0598, acc: 97.6133, loss_bbox: 0.0870, loss: 0.1525
2022-06-20 17:11:56,703 - mmdet - INFO - Epoch [10][800/1604]	lr: 5.000e-04, eta: 0:58:26, time: 0.452, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0041, loss_cls: 0.0548, acc: 97.7656, loss_bbox: 0.0848, loss: 0.1466
2022-06-20 17:12:19,462 - mmdet - INFO - Epoch [10][850/1604]	lr: 5.000e-04, eta: 0:58:01, time: 0.455, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0034, loss_cls: 0.0438, acc: 98.1992, loss_bbox: 0.0688, loss: 0.1172
2022-06-20 17:12:42,876 - mmdet - INFO - Epoch [10][900/1604]	lr: 5.000e-04, eta: 0:57:36, time: 0.468, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0050, loss_cls: 0.0648, acc: 97.4492, loss_bbox: 0.1007, loss: 0.1733
2022-06-20 17:13:02,459 - mmdet - INFO - Epoch [10][950/1604]	lr: 5.000e-04, eta: 0:57:10, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0039, loss_cls: 0.0587, acc: 97.4023, loss_bbox: 0.0912, loss: 0.1562
2022-06-20 17:13:22,229 - mmdet - INFO - Epoch [10][1000/1604]	lr: 5.000e-04, eta: 0:56:43, time: 0.395, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0051, loss_cls: 0.0495, acc: 97.8516, loss_bbox: 0.0881, loss: 0.1441
2022-06-20 17:13:41,841 - mmdet - INFO - Epoch [10][1050/1604]	lr: 5.000e-04, eta: 0:56:17, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0037, loss_cls: 0.0623, acc: 97.5117, loss_bbox: 0.0979, loss: 0.1674
2022-06-20 17:14:09,588 - mmdet - INFO - Epoch [10][1100/1604]	lr: 5.000e-04, eta: 0:55:54, time: 0.555, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0043, loss_cls: 0.0574, acc: 97.6133, loss_bbox: 0.0911, loss: 0.1544
2022-06-20 17:14:36,274 - mmdet - INFO - Epoch [10][1150/1604]	lr: 5.000e-04, eta: 0:55:31, time: 0.534, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0040, loss_cls: 0.0564, acc: 97.5352, loss_bbox: 0.0827, loss: 0.1458
2022-06-20 17:15:00,913 - mmdet - INFO - Epoch [10][1200/1604]	lr: 5.000e-04, eta: 0:55:07, time: 0.493, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0050, loss_cls: 0.0615, acc: 97.4609, loss_bbox: 0.0957, loss: 0.1648
2022-06-20 17:15:23,057 - mmdet - INFO - Epoch [10][1250/1604]	lr: 5.000e-04, eta: 0:54:42, time: 0.443, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0031, loss_cls: 0.0513, acc: 97.8281, loss_bbox: 0.0866, loss: 0.1430
2022-06-20 17:15:47,357 - mmdet - INFO - Epoch [10][1300/1604]	lr: 5.000e-04, eta: 0:54:18, time: 0.486, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0052, loss_cls: 0.0639, acc: 97.4961, loss_bbox: 0.0958, loss: 0.1676
2022-06-20 17:16:08,561 - mmdet - INFO - Epoch [10][1350/1604]	lr: 5.000e-04, eta: 0:53:52, time: 0.424, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, loss_cls: 0.0762, acc: 97.1406, loss_bbox: 0.1041, loss: 0.1871
2022-06-20 17:16:35,999 - mmdet - INFO - Epoch [10][1400/1604]	lr: 5.000e-04, eta: 0:53:29, time: 0.549, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0057, loss_cls: 0.0604, acc: 97.6914, loss_bbox: 0.0867, loss: 0.1559
2022-06-20 17:17:05,001 - mmdet - INFO - Epoch [10][1450/1604]	lr: 5.000e-04, eta: 0:53:07, time: 0.580, data_time: 0.008, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0047, loss_cls: 0.0636, acc: 97.3477, loss_bbox: 0.0903, loss: 0.1610
2022-06-20 17:17:30,410 - mmdet - INFO - Epoch [10][1500/1604]	lr: 5.000e-04, eta: 0:52:43, time: 0.508, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0034, loss_cls: 0.0508, acc: 97.9805, loss_bbox: 0.0702, loss: 0.1266
2022-06-20 17:17:52,454 - mmdet - INFO - Epoch [10][1550/1604]	lr: 5.000e-04, eta: 0:52:18, time: 0.441, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0049, loss_cls: 0.0542, acc: 97.7773, loss_bbox: 0.0824, loss: 0.1438
2022-06-20 17:18:12,122 - mmdet - INFO - Epoch [10][1600/1604]	lr: 5.000e-04, eta: 0:51:52, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0036, loss_cls: 0.0712, acc: 97.4336, loss_bbox: 0.0882, loss: 0.1669
2022-06-20 17:18:13,911 - mmdet - INFO - Saving checkpoint at 10 epochs
2022-06-20 17:19:42,710 - mmdet - INFO - Evaluating bbox...
2022-06-20 17:19:43,517 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.533 | 2_hanfeng | 0.469 | 3_yueyawan | 0.633 |
| 4_shuiban   | 0.424 | 5_youban  | 0.232 | 6_siban    | 0.289 |
| 7_yiwu      | 0.142 | 8_yahen   | 0.162 | 9_zhehen   | 0.181 |
| 10_yaozhe   | 0.385 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 17:19:43,527 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 17:19:43,527 - mmdet - INFO - Epoch(val) [10][688]	bbox_mAP: 0.3450, bbox_mAP_50: 0.7110, bbox_mAP_75: 0.2770, bbox_mAP_s: 0.1050, bbox_mAP_m: 0.1900, bbox_mAP_l: 0.3490, bbox_mAP_copypaste: 0.345 0.711 0.277 0.105 0.190 0.349
2022-06-20 17:20:23,084 - mmdet - INFO - Epoch [11][50/1604]	lr: 5.000e-04, eta: 0:51:31, time: 0.791, data_time: 0.054, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0040, loss_cls: 0.0512, acc: 97.8789, loss_bbox: 0.0773, loss: 0.1350
2022-06-20 17:20:50,771 - mmdet - INFO - Epoch [11][100/1604]	lr: 5.000e-04, eta: 0:51:08, time: 0.554, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0024, loss_cls: 0.0451, acc: 98.2188, loss_bbox: 0.0719, loss: 0.1211
2022-06-20 17:21:19,816 - mmdet - INFO - Epoch [11][150/1604]	lr: 5.000e-04, eta: 0:50:46, time: 0.581, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0029, loss_cls: 0.0590, acc: 97.5625, loss_bbox: 0.0866, loss: 0.1504
2022-06-20 17:21:39,479 - mmdet - INFO - Epoch [11][200/1604]	lr: 5.000e-04, eta: 0:50:20, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0025, loss_cls: 0.0487, acc: 98.1836, loss_bbox: 0.0767, loss: 0.1298
2022-06-20 17:21:58,829 - mmdet - INFO - Epoch [11][250/1604]	lr: 5.000e-04, eta: 0:49:53, time: 0.387, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0033, loss_cls: 0.0556, acc: 97.7617, loss_bbox: 0.0921, loss: 0.1536
2022-06-20 17:22:21,418 - mmdet - INFO - Epoch [11][300/1604]	lr: 5.000e-04, eta: 0:49:29, time: 0.452, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0032, loss_cls: 0.0552, acc: 97.6758, loss_bbox: 0.0843, loss: 0.1442
2022-06-20 17:22:41,028 - mmdet - INFO - Epoch [11][350/1604]	lr: 5.000e-04, eta: 0:49:03, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0030, loss_cls: 0.0436, acc: 98.2617, loss_bbox: 0.0700, loss: 0.1173
2022-06-20 17:23:02,868 - mmdet - INFO - Epoch [11][400/1604]	lr: 5.000e-04, eta: 0:48:37, time: 0.437, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0039, loss_cls: 0.0464, acc: 98.2422, loss_bbox: 0.0700, loss: 0.1235
2022-06-20 17:23:23,872 - mmdet - INFO - Epoch [11][450/1604]	lr: 5.000e-04, eta: 0:48:12, time: 0.420, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0051, loss_cls: 0.0611, acc: 97.5781, loss_bbox: 0.0993, loss: 0.1682
2022-06-20 17:23:45,039 - mmdet - INFO - Epoch [11][500/1604]	lr: 5.000e-04, eta: 0:47:47, time: 0.423, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0050, loss_cls: 0.0781, acc: 97.3164, loss_bbox: 0.0890, loss: 0.1758
2022-06-20 17:24:14,089 - mmdet - INFO - Epoch [11][550/1604]	lr: 5.000e-04, eta: 0:47:24, time: 0.581, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0039, loss_cls: 0.0498, acc: 98.0625, loss_bbox: 0.0765, loss: 0.1323
2022-06-20 17:24:39,349 - mmdet - INFO - Epoch [11][600/1604]	lr: 5.000e-04, eta: 0:47:00, time: 0.505, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0033, loss_cls: 0.0473, acc: 97.9609, loss_bbox: 0.0767, loss: 0.1287
2022-06-20 17:24:58,658 - mmdet - INFO - Epoch [11][650/1604]	lr: 5.000e-04, eta: 0:46:34, time: 0.386, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0039, loss_cls: 0.0584, acc: 97.5547, loss_bbox: 0.0925, loss: 0.1575
2022-06-20 17:25:18,067 - mmdet - INFO - Epoch [11][700/1604]	lr: 5.000e-04, eta: 0:46:08, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0049, loss_cls: 0.0617, acc: 97.4023, loss_bbox: 0.0848, loss: 0.1531
2022-06-20 17:25:39,834 - mmdet - INFO - Epoch [11][750/1604]	lr: 5.000e-04, eta: 0:45:43, time: 0.435, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0065, loss_cls: 0.0623, acc: 97.5312, loss_bbox: 0.0956, loss: 0.1695
2022-06-20 17:25:59,774 - mmdet - INFO - Epoch [11][800/1604]	lr: 5.000e-04, eta: 0:45:18, time: 0.399, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0022, loss_cls: 0.0512, acc: 97.8945, loss_bbox: 0.0758, loss: 0.1303
2022-06-20 17:26:19,354 - mmdet - INFO - Epoch [11][850/1604]	lr: 5.000e-04, eta: 0:44:52, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0022, loss_cls: 0.0527, acc: 97.9727, loss_bbox: 0.0805, loss: 0.1376
2022-06-20 17:26:39,352 - mmdet - INFO - Epoch [11][900/1604]	lr: 5.000e-04, eta: 0:44:26, time: 0.400, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0041, loss_cls: 0.0592, acc: 97.5781, loss_bbox: 0.0930, loss: 0.1596
2022-06-20 17:26:58,950 - mmdet - INFO - Epoch [11][950/1604]	lr: 5.000e-04, eta: 0:44:01, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0038, loss_cls: 0.0526, acc: 97.8164, loss_bbox: 0.0844, loss: 0.1427
2022-06-20 17:27:20,139 - mmdet - INFO - Epoch [11][1000/1604]	lr: 5.000e-04, eta: 0:43:36, time: 0.424, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0039, loss_cls: 0.0478, acc: 98.1133, loss_bbox: 0.0737, loss: 0.1271
2022-06-20 17:27:40,537 - mmdet - INFO - Epoch [11][1050/1604]	lr: 5.000e-04, eta: 0:43:10, time: 0.408, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0037, loss_cls: 0.0636, acc: 97.5117, loss_bbox: 0.0947, loss: 0.1635
2022-06-20 17:28:03,018 - mmdet - INFO - Epoch [11][1100/1604]	lr: 5.000e-04, eta: 0:42:46, time: 0.450, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0033, loss_cls: 0.0716, acc: 97.4062, loss_bbox: 0.0913, loss: 0.1683
2022-06-20 17:28:22,575 - mmdet - INFO - Epoch [11][1150/1604]	lr: 5.000e-04, eta: 0:42:20, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0030, loss_cls: 0.0498, acc: 97.9062, loss_bbox: 0.0734, loss: 0.1279
2022-06-20 17:28:42,044 - mmdet - INFO - Epoch [11][1200/1604]	lr: 5.000e-04, eta: 0:41:55, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0042, loss_cls: 0.0625, acc: 97.4570, loss_bbox: 0.1060, loss: 0.1752
2022-06-20 17:29:06,973 - mmdet - INFO - Epoch [11][1250/1604]	lr: 5.000e-04, eta: 0:41:31, time: 0.499, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0032, loss_cls: 0.0465, acc: 98.1758, loss_bbox: 0.0710, loss: 0.1232
2022-06-20 17:29:29,117 - mmdet - INFO - Epoch [11][1300/1604]	lr: 5.000e-04, eta: 0:41:06, time: 0.443, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0046, loss_cls: 0.0595, acc: 97.6602, loss_bbox: 0.0906, loss: 0.1564
2022-06-20 17:29:48,695 - mmdet - INFO - Epoch [11][1350/1604]	lr: 5.000e-04, eta: 0:40:41, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0051, loss_cls: 0.0538, acc: 97.9336, loss_bbox: 0.0857, loss: 0.1476
2022-06-20 17:30:08,207 - mmdet - INFO - Epoch [11][1400/1604]	lr: 5.000e-04, eta: 0:40:15, time: 0.390, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0038, loss_cls: 0.0685, acc: 97.1094, loss_bbox: 0.0995, loss: 0.1750
2022-06-20 17:30:27,609 - mmdet - INFO - Epoch [11][1450/1604]	lr: 5.000e-04, eta: 0:39:50, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0039, loss_cls: 0.0524, acc: 97.9375, loss_bbox: 0.0790, loss: 0.1370
2022-06-20 17:30:51,017 - mmdet - INFO - Epoch [11][1500/1604]	lr: 5.000e-04, eta: 0:39:26, time: 0.468, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0035, loss_cls: 0.0630, acc: 97.3555, loss_bbox: 0.0975, loss: 0.1655
2022-06-20 17:31:11,474 - mmdet - INFO - Epoch [11][1550/1604]	lr: 5.000e-04, eta: 0:39:00, time: 0.409, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0047, loss_cls: 0.0520, acc: 97.8711, loss_bbox: 0.0819, loss: 0.1407
2022-06-20 17:31:30,959 - mmdet - INFO - Epoch [11][1600/1604]	lr: 5.000e-04, eta: 0:38:35, time: 0.390, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0058, loss_cls: 0.0598, acc: 97.6406, loss_bbox: 0.1002, loss: 0.1689
2022-06-20 17:31:32,602 - mmdet - INFO - Saving checkpoint at 11 epochs
2022-06-20 17:33:00,797 - mmdet - INFO - Evaluating bbox...
2022-06-20 17:33:01,490 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.551 | 2_hanfeng | 0.481 | 3_yueyawan | 0.635 |
| 4_shuiban   | 0.441 | 5_youban  | 0.233 | 6_siban    | 0.285 |
| 7_yiwu      | 0.155 | 8_yahen   | 0.153 | 9_zhehen   | 0.210 |
| 10_yaozhe   | 0.404 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 17:33:01,500 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 17:33:01,500 - mmdet - INFO - Epoch(val) [11][688]	bbox_mAP: 0.3550, bbox_mAP_50: 0.7160, bbox_mAP_75: 0.2970, bbox_mAP_s: 0.0630, bbox_mAP_m: 0.2000, bbox_mAP_l: 0.3600, bbox_mAP_copypaste: 0.355 0.716 0.297 0.063 0.200 0.360
2022-06-20 17:33:31,540 - mmdet - INFO - Epoch [12][50/1604]	lr: 5.000e-05, eta: 0:38:10, time: 0.600, data_time: 0.052, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0030, loss_cls: 0.0496, acc: 98.0391, loss_bbox: 0.0702, loss: 0.1248
2022-06-20 17:33:58,450 - mmdet - INFO - Epoch [12][100/1604]	lr: 5.000e-05, eta: 0:37:47, time: 0.538, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0043, loss_cls: 0.0652, acc: 97.4531, loss_bbox: 0.0962, loss: 0.1679
2022-06-20 17:34:18,043 - mmdet - INFO - Epoch [12][150/1604]	lr: 5.000e-05, eta: 0:37:22, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0044, loss_cls: 0.0662, acc: 97.2227, loss_bbox: 0.1023, loss: 0.1748
2022-06-20 17:34:39,871 - mmdet - INFO - Epoch [12][200/1604]	lr: 5.000e-05, eta: 0:36:57, time: 0.437, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0032, loss_cls: 0.0493, acc: 97.9336, loss_bbox: 0.0814, loss: 0.1360
2022-06-20 17:35:01,062 - mmdet - INFO - Epoch [12][250/1604]	lr: 5.000e-05, eta: 0:36:32, time: 0.424, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0041, loss_cls: 0.0465, acc: 98.1836, loss_bbox: 0.0723, loss: 0.1252
2022-06-20 17:35:24,942 - mmdet - INFO - Epoch [12][300/1604]	lr: 5.000e-05, eta: 0:36:08, time: 0.478, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0045, loss_cls: 0.0586, acc: 97.6523, loss_bbox: 0.0930, loss: 0.1587
2022-06-20 17:35:54,253 - mmdet - INFO - Epoch [12][350/1604]	lr: 5.000e-05, eta: 0:35:46, time: 0.586, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0038, loss_cls: 0.0474, acc: 98.0273, loss_bbox: 0.0826, loss: 0.1358
2022-06-20 17:36:14,285 - mmdet - INFO - Epoch [12][400/1604]	lr: 5.000e-05, eta: 0:35:21, time: 0.401, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0053, loss_cls: 0.0618, acc: 97.5234, loss_bbox: 0.0861, loss: 0.1552
2022-06-20 17:36:36,733 - mmdet - INFO - Epoch [12][450/1604]	lr: 5.000e-05, eta: 0:34:56, time: 0.449, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0024, loss_cls: 0.0411, acc: 98.3047, loss_bbox: 0.0666, loss: 0.1114
2022-06-20 17:36:59,694 - mmdet - INFO - Epoch [12][500/1604]	lr: 5.000e-05, eta: 0:34:32, time: 0.459, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0029, loss_cls: 0.0563, acc: 97.7305, loss_bbox: 0.0956, loss: 0.1564
2022-06-20 17:37:25,074 - mmdet - INFO - Epoch [12][550/1604]	lr: 5.000e-05, eta: 0:34:08, time: 0.508, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0041, loss_cls: 0.0619, acc: 97.5195, loss_bbox: 0.0869, loss: 0.1566
2022-06-20 17:37:44,934 - mmdet - INFO - Epoch [12][600/1604]	lr: 5.000e-05, eta: 0:33:43, time: 0.397, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0023, loss_cls: 0.0435, acc: 98.2422, loss_bbox: 0.0675, loss: 0.1148
2022-06-20 17:38:05,561 - mmdet - INFO - Epoch [12][650/1604]	lr: 5.000e-05, eta: 0:33:18, time: 0.413, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0038, loss_cls: 0.0521, acc: 97.8203, loss_bbox: 0.0884, loss: 0.1460
2022-06-20 17:38:34,405 - mmdet - INFO - Epoch [12][700/1604]	lr: 5.000e-05, eta: 0:32:55, time: 0.577, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0043, loss_cls: 0.0572, acc: 97.6211, loss_bbox: 0.0909, loss: 0.1552
2022-06-20 17:38:56,339 - mmdet - INFO - Epoch [12][750/1604]	lr: 5.000e-05, eta: 0:32:31, time: 0.439, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0036, loss_cls: 0.0672, acc: 97.5039, loss_bbox: 0.0890, loss: 0.1627
2022-06-20 17:39:24,690 - mmdet - INFO - Epoch [12][800/1604]	lr: 5.000e-05, eta: 0:32:08, time: 0.567, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0036, loss_cls: 0.0453, acc: 98.0664, loss_bbox: 0.0712, loss: 0.1229
2022-06-20 17:39:49,978 - mmdet - INFO - Epoch [12][850/1604]	lr: 5.000e-05, eta: 0:31:44, time: 0.506, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0031, loss_cls: 0.0493, acc: 97.9297, loss_bbox: 0.0792, loss: 0.1331
2022-06-20 17:40:11,417 - mmdet - INFO - Epoch [12][900/1604]	lr: 5.000e-05, eta: 0:31:20, time: 0.429, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0036, loss_cls: 0.0532, acc: 97.6992, loss_bbox: 0.0900, loss: 0.1481
2022-06-20 17:40:30,966 - mmdet - INFO - Epoch [12][950/1604]	lr: 5.000e-05, eta: 0:30:55, time: 0.391, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0032, loss_cls: 0.0586, acc: 97.8516, loss_bbox: 0.0807, loss: 0.1448
2022-06-20 17:40:50,659 - mmdet - INFO - Epoch [12][1000/1604]	lr: 5.000e-05, eta: 0:30:30, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0033, loss_cls: 0.0548, acc: 97.7148, loss_bbox: 0.0810, loss: 0.1410
2022-06-20 17:41:10,260 - mmdet - INFO - Epoch [12][1050/1604]	lr: 5.000e-05, eta: 0:30:05, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0053, loss_cls: 0.0511, acc: 98.0469, loss_bbox: 0.0717, loss: 0.1307
2022-06-20 17:41:33,611 - mmdet - INFO - Epoch [12][1100/1604]	lr: 5.000e-05, eta: 0:29:41, time: 0.467, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0032, loss_cls: 0.0565, acc: 97.8164, loss_bbox: 0.0742, loss: 0.1352
2022-06-20 17:41:53,617 - mmdet - INFO - Epoch [12][1150/1604]	lr: 5.000e-05, eta: 0:29:16, time: 0.400, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0043, loss_cls: 0.0515, acc: 97.8516, loss_bbox: 0.0833, loss: 0.1407
2022-06-20 17:42:13,243 - mmdet - INFO - Epoch [12][1200/1604]	lr: 5.000e-05, eta: 0:28:51, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0029, loss_cls: 0.0494, acc: 98.0039, loss_bbox: 0.0798, loss: 0.1335
2022-06-20 17:42:32,888 - mmdet - INFO - Epoch [12][1250/1604]	lr: 5.000e-05, eta: 0:28:26, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0031, loss_cls: 0.0439, acc: 98.2188, loss_bbox: 0.0685, loss: 0.1174
2022-06-20 17:42:52,575 - mmdet - INFO - Epoch [12][1300/1604]	lr: 5.000e-05, eta: 0:28:02, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0031, loss_cls: 0.0450, acc: 98.0234, loss_bbox: 0.0756, loss: 0.1251
2022-06-20 17:43:12,566 - mmdet - INFO - Epoch [12][1350/1604]	lr: 5.000e-05, eta: 0:27:37, time: 0.400, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0031, loss_cls: 0.0510, acc: 97.9453, loss_bbox: 0.0794, loss: 0.1357
2022-06-20 17:43:32,094 - mmdet - INFO - Epoch [12][1400/1604]	lr: 5.000e-05, eta: 0:27:12, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0033, loss_cls: 0.0424, acc: 98.1719, loss_bbox: 0.0725, loss: 0.1200
2022-06-20 17:43:51,747 - mmdet - INFO - Epoch [12][1450/1604]	lr: 5.000e-05, eta: 0:26:47, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0032, loss_cls: 0.0495, acc: 97.9688, loss_bbox: 0.0842, loss: 0.1389
2022-06-20 17:44:12,775 - mmdet - INFO - Epoch [12][1500/1604]	lr: 5.000e-05, eta: 0:26:23, time: 0.421, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0034, loss_cls: 0.0514, acc: 97.9531, loss_bbox: 0.0761, loss: 0.1332
2022-06-20 17:44:32,089 - mmdet - INFO - Epoch [12][1550/1604]	lr: 5.000e-05, eta: 0:25:58, time: 0.386, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0043, loss_cls: 0.0596, acc: 97.5352, loss_bbox: 0.0941, loss: 0.1603
2022-06-20 17:44:51,561 - mmdet - INFO - Epoch [12][1600/1604]	lr: 5.000e-05, eta: 0:25:34, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0045, loss_cls: 0.0455, acc: 98.1094, loss_bbox: 0.0676, loss: 0.1190
2022-06-20 17:44:53,213 - mmdet - INFO - Saving checkpoint at 12 epochs
2022-06-20 17:46:24,649 - mmdet - INFO - Evaluating bbox...
2022-06-20 17:46:25,399 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.561 | 2_hanfeng | 0.478 | 3_yueyawan | 0.624 |
| 4_shuiban   | 0.437 | 5_youban  | 0.237 | 6_siban    | 0.293 |
| 7_yiwu      | 0.151 | 8_yahen   | 0.161 | 9_zhehen   | 0.199 |
| 10_yaozhe   | 0.392 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 17:46:25,409 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 17:46:25,410 - mmdet - INFO - Epoch(val) [12][688]	bbox_mAP: 0.3530, bbox_mAP_50: 0.7080, bbox_mAP_75: 0.2960, bbox_mAP_s: 0.0790, bbox_mAP_m: 0.2020, bbox_mAP_l: 0.3580, bbox_mAP_copypaste: 0.353 0.708 0.296 0.079 0.202 0.358
2022-06-20 17:46:54,924 - mmdet - INFO - Epoch [13][50/1604]	lr: 5.000e-05, eta: 0:25:09, time: 0.590, data_time: 0.050, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0041, loss_cls: 0.0546, acc: 97.8125, loss_bbox: 0.0848, loss: 0.1455
2022-06-20 17:47:16,055 - mmdet - INFO - Epoch [13][100/1604]	lr: 5.000e-05, eta: 0:24:44, time: 0.423, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0023, loss_cls: 0.0549, acc: 97.7227, loss_bbox: 0.0828, loss: 0.1439
2022-06-20 17:47:35,674 - mmdet - INFO - Epoch [13][150/1604]	lr: 5.000e-05, eta: 0:24:20, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0036, loss_cls: 0.0606, acc: 97.6914, loss_bbox: 0.0897, loss: 0.1562
2022-06-20 17:47:59,595 - mmdet - INFO - Epoch [13][200/1604]	lr: 5.000e-05, eta: 0:23:56, time: 0.478, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0033, loss_cls: 0.0565, acc: 97.7852, loss_bbox: 0.0913, loss: 0.1535
2022-06-20 17:48:26,977 - mmdet - INFO - Epoch [13][250/1604]	lr: 5.000e-05, eta: 0:23:32, time: 0.548, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0040, loss_cls: 0.0519, acc: 97.8320, loss_bbox: 0.0685, loss: 0.1258
2022-06-20 17:48:49,366 - mmdet - INFO - Epoch [13][300/1604]	lr: 5.000e-05, eta: 0:23:08, time: 0.448, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0037, loss_cls: 0.0499, acc: 97.9492, loss_bbox: 0.0770, loss: 0.1326
2022-06-20 17:49:15,173 - mmdet - INFO - Epoch [13][350/1604]	lr: 5.000e-05, eta: 0:22:45, time: 0.516, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0038, loss_cls: 0.0482, acc: 98.0859, loss_bbox: 0.0753, loss: 0.1291
2022-06-20 17:49:36,984 - mmdet - INFO - Epoch [13][400/1604]	lr: 5.000e-05, eta: 0:22:21, time: 0.436, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0022, loss_cls: 0.0487, acc: 98.0430, loss_bbox: 0.0732, loss: 0.1268
2022-06-20 17:49:56,597 - mmdet - INFO - Epoch [13][450/1604]	lr: 5.000e-05, eta: 0:21:56, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0027, loss_cls: 0.0399, acc: 98.3516, loss_bbox: 0.0660, loss: 0.1100
2022-06-20 17:50:17,974 - mmdet - INFO - Epoch [13][500/1604]	lr: 5.000e-05, eta: 0:21:32, time: 0.428, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0039, loss_cls: 0.0534, acc: 98.0195, loss_bbox: 0.0788, loss: 0.1379
2022-06-20 17:50:37,733 - mmdet - INFO - Epoch [13][550/1604]	lr: 5.000e-05, eta: 0:21:07, time: 0.395, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0022, loss_cls: 0.0565, acc: 97.8906, loss_bbox: 0.0826, loss: 0.1429
2022-06-20 17:50:59,679 - mmdet - INFO - Epoch [13][600/1604]	lr: 5.000e-05, eta: 0:20:43, time: 0.439, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0039, loss_cls: 0.0458, acc: 98.1367, loss_bbox: 0.0725, loss: 0.1238
2022-06-20 17:51:21,448 - mmdet - INFO - Epoch [13][650/1604]	lr: 5.000e-05, eta: 0:20:19, time: 0.435, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0030, loss_cls: 0.0429, acc: 98.2266, loss_bbox: 0.0617, loss: 0.1085
2022-06-20 17:51:43,775 - mmdet - INFO - Epoch [13][700/1604]	lr: 5.000e-05, eta: 0:19:55, time: 0.447, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0030, loss_cls: 0.0435, acc: 98.3086, loss_bbox: 0.0737, loss: 0.1217
2022-06-20 17:52:06,358 - mmdet - INFO - Epoch [13][750/1604]	lr: 5.000e-05, eta: 0:19:31, time: 0.452, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0039, loss_cls: 0.0644, acc: 97.3320, loss_bbox: 0.0949, loss: 0.1654
2022-06-20 17:52:26,011 - mmdet - INFO - Epoch [13][800/1604]	lr: 5.000e-05, eta: 0:19:07, time: 0.393, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0031, loss_cls: 0.0455, acc: 98.0664, loss_bbox: 0.0710, loss: 0.1205
2022-06-20 17:52:47,393 - mmdet - INFO - Epoch [13][850/1604]	lr: 5.000e-05, eta: 0:18:43, time: 0.428, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0036, loss_cls: 0.0462, acc: 98.1953, loss_bbox: 0.0766, loss: 0.1281
2022-06-20 17:53:07,101 - mmdet - INFO - Epoch [13][900/1604]	lr: 5.000e-05, eta: 0:18:18, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0040, loss_cls: 0.0651, acc: 97.2383, loss_bbox: 0.0966, loss: 0.1684
2022-06-20 17:53:26,854 - mmdet - INFO - Epoch [13][950/1604]	lr: 5.000e-05, eta: 0:17:54, time: 0.395, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0032, loss_cls: 0.0457, acc: 97.9766, loss_bbox: 0.0749, loss: 0.1249
2022-06-20 17:53:54,041 - mmdet - INFO - Epoch [13][1000/1604]	lr: 5.000e-05, eta: 0:17:31, time: 0.544, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, loss_cls: 0.0586, acc: 97.4297, loss_bbox: 0.0884, loss: 0.1531
2022-06-20 17:54:23,091 - mmdet - INFO - Epoch [13][1050/1604]	lr: 5.000e-05, eta: 0:17:08, time: 0.581, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0036, loss_cls: 0.0559, acc: 97.6367, loss_bbox: 0.0845, loss: 0.1465
2022-06-20 17:54:45,501 - mmdet - INFO - Epoch [13][1100/1604]	lr: 5.000e-05, eta: 0:16:44, time: 0.448, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0040, loss_cls: 0.0539, acc: 97.7812, loss_bbox: 0.0940, loss: 0.1538
2022-06-20 17:55:05,196 - mmdet - INFO - Epoch [13][1150/1604]	lr: 5.000e-05, eta: 0:16:19, time: 0.394, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, loss_cls: 0.0539, acc: 97.8672, loss_bbox: 0.0790, loss: 0.1401
2022-06-20 17:55:24,824 - mmdet - INFO - Epoch [13][1200/1604]	lr: 5.000e-05, eta: 0:15:55, time: 0.392, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0028, loss_cls: 0.0465, acc: 98.1914, loss_bbox: 0.0762, loss: 0.1274
2022-06-20 17:55:44,477 - mmdet - INFO - Epoch [13][1250/1604]	lr: 5.000e-05, eta: 0:15:31, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0048, loss_cls: 0.0683, acc: 97.2969, loss_bbox: 0.0961, loss: 0.1710
2022-06-20 17:56:10,231 - mmdet - INFO - Epoch [13][1300/1604]	lr: 5.000e-05, eta: 0:15:07, time: 0.515, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0028, loss_cls: 0.0410, acc: 98.2344, loss_bbox: 0.0694, loss: 0.1144
2022-06-20 17:56:31,363 - mmdet - INFO - Epoch [13][1350/1604]	lr: 5.000e-05, eta: 0:14:43, time: 0.423, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0035, loss_cls: 0.0568, acc: 97.6914, loss_bbox: 0.0875, loss: 0.1495
2022-06-20 17:56:56,540 - mmdet - INFO - Epoch [13][1400/1604]	lr: 5.000e-05, eta: 0:14:20, time: 0.504, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0038, loss_cls: 0.0563, acc: 97.7344, loss_bbox: 0.0857, loss: 0.1480
2022-06-20 17:57:18,273 - mmdet - INFO - Epoch [13][1450/1604]	lr: 5.000e-05, eta: 0:13:56, time: 0.435, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0032, loss_cls: 0.0486, acc: 98.0156, loss_bbox: 0.0725, loss: 0.1270
2022-06-20 17:57:37,885 - mmdet - INFO - Epoch [13][1500/1604]	lr: 5.000e-05, eta: 0:13:32, time: 0.392, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0042, loss_cls: 0.0617, acc: 97.4375, loss_bbox: 0.0965, loss: 0.1643
2022-06-20 17:57:57,394 - mmdet - INFO - Epoch [13][1550/1604]	lr: 5.000e-05, eta: 0:13:07, time: 0.390, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0054, loss_cls: 0.0603, acc: 97.3164, loss_bbox: 0.0967, loss: 0.1642
2022-06-20 17:58:23,478 - mmdet - INFO - Epoch [13][1600/1604]	lr: 5.000e-05, eta: 0:12:44, time: 0.522, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0032, loss_cls: 0.0488, acc: 97.9922, loss_bbox: 0.0751, loss: 0.1293
2022-06-20 17:58:25,131 - mmdet - INFO - Saving checkpoint at 13 epochs
2022-06-20 17:59:59,306 - mmdet - INFO - Evaluating bbox...
2022-06-20 18:00:00,053 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.560 | 2_hanfeng | 0.476 | 3_yueyawan | 0.630 |
| 4_shuiban   | 0.435 | 5_youban  | 0.236 | 6_siban    | 0.293 |
| 7_yiwu      | 0.151 | 8_yahen   | 0.159 | 9_zhehen   | 0.195 |
| 10_yaozhe   | 0.392 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 18:00:00,063 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 18:00:00,064 - mmdet - INFO - Epoch(val) [13][688]	bbox_mAP: 0.3530, bbox_mAP_50: 0.7070, bbox_mAP_75: 0.2980, bbox_mAP_s: 0.0840, bbox_mAP_m: 0.2020, bbox_mAP_l: 0.3570, bbox_mAP_copypaste: 0.353 0.707 0.298 0.084 0.202 0.357
2022-06-20 18:00:31,089 - mmdet - INFO - Epoch [14][50/1604]	lr: 5.000e-05, eta: 0:12:19, time: 0.620, data_time: 0.052, memory: 8933, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0034, loss_cls: 0.0550, acc: 97.8359, loss_bbox: 0.0837, loss: 0.1432
2022-06-20 18:00:52,980 - mmdet - INFO - Epoch [14][100/1604]	lr: 5.000e-05, eta: 0:11:55, time: 0.438, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, loss_cls: 0.0504, acc: 97.9883, loss_bbox: 0.0795, loss: 0.1358
2022-06-20 18:01:15,031 - mmdet - INFO - Epoch [14][150/1604]	lr: 5.000e-05, eta: 0:11:31, time: 0.441, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0030, loss_cls: 0.0486, acc: 98.0117, loss_bbox: 0.0652, loss: 0.1180
2022-06-20 18:01:34,660 - mmdet - INFO - Epoch [14][200/1604]	lr: 5.000e-05, eta: 0:11:07, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0040, loss_cls: 0.0610, acc: 97.3828, loss_bbox: 0.0966, loss: 0.1630
2022-06-20 18:01:54,891 - mmdet - INFO - Epoch [14][250/1604]	lr: 5.000e-05, eta: 0:10:43, time: 0.405, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0046, loss_cls: 0.0572, acc: 97.6758, loss_bbox: 0.0873, loss: 0.1509
2022-06-20 18:02:21,712 - mmdet - INFO - Epoch [14][300/1604]	lr: 5.000e-05, eta: 0:10:19, time: 0.536, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0031, loss_cls: 0.0545, acc: 97.9531, loss_bbox: 0.0777, loss: 0.1378
2022-06-20 18:02:46,506 - mmdet - INFO - Epoch [14][350/1604]	lr: 5.000e-05, eta: 0:09:55, time: 0.496, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0032, loss_cls: 0.0495, acc: 97.9922, loss_bbox: 0.0766, loss: 0.1314
2022-06-20 18:03:16,190 - mmdet - INFO - Epoch [14][400/1604]	lr: 5.000e-05, eta: 0:09:32, time: 0.594, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0043, loss_cls: 0.0594, acc: 97.8125, loss_bbox: 0.0847, loss: 0.1512
2022-06-20 18:03:54,864 - mmdet - INFO - Epoch [14][450/1604]	lr: 5.000e-05, eta: 0:09:09, time: 0.773, data_time: 0.011, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0031, loss_cls: 0.0546, acc: 97.7500, loss_bbox: 0.0820, loss: 0.1413
2022-06-20 18:04:52,023 - mmdet - INFO - Epoch [14][500/1604]	lr: 5.000e-05, eta: 0:08:47, time: 1.143, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0036, loss_cls: 0.0495, acc: 97.8945, loss_bbox: 0.0758, loss: 0.1306
2022-06-20 18:05:26,498 - mmdet - INFO - Epoch [14][550/1604]	lr: 5.000e-05, eta: 0:08:24, time: 0.689, data_time: 0.010, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0038, loss_cls: 0.0580, acc: 97.5234, loss_bbox: 0.0896, loss: 0.1537
2022-06-20 18:05:52,622 - mmdet - INFO - Epoch [14][600/1604]	lr: 5.000e-05, eta: 0:08:00, time: 0.522, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0027, loss_cls: 0.0464, acc: 98.2305, loss_bbox: 0.0654, loss: 0.1165
2022-06-20 18:06:25,534 - mmdet - INFO - Epoch [14][650/1604]	lr: 5.000e-05, eta: 0:07:36, time: 0.658, data_time: 0.009, memory: 8933, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0037, loss_cls: 0.0496, acc: 97.9727, loss_bbox: 0.0692, loss: 0.1244
2022-06-20 18:07:02,343 - mmdet - INFO - Epoch [14][700/1604]	lr: 5.000e-05, eta: 0:07:13, time: 0.736, data_time: 0.011, memory: 8933, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0031, loss_cls: 0.0563, acc: 97.6211, loss_bbox: 0.1049, loss: 0.1657
2022-06-20 18:07:22,647 - mmdet - INFO - Epoch [14][750/1604]	lr: 5.000e-05, eta: 0:06:49, time: 0.406, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0029, loss_cls: 0.0552, acc: 98.0430, loss_bbox: 0.0624, loss: 0.1225
2022-06-20 18:07:42,057 - mmdet - INFO - Epoch [14][800/1604]	lr: 5.000e-05, eta: 0:06:25, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, loss_cls: 0.0588, acc: 97.5625, loss_bbox: 0.0887, loss: 0.1534
2022-06-20 18:08:01,459 - mmdet - INFO - Epoch [14][850/1604]	lr: 5.000e-05, eta: 0:06:01, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0037, loss_cls: 0.0498, acc: 97.8203, loss_bbox: 0.0760, loss: 0.1317
2022-06-20 18:08:20,961 - mmdet - INFO - Epoch [14][900/1604]	lr: 5.000e-05, eta: 0:05:36, time: 0.390, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0045, loss_cls: 0.0409, acc: 98.4023, loss_bbox: 0.0701, loss: 0.1170
2022-06-20 18:08:40,338 - mmdet - INFO - Epoch [14][950/1604]	lr: 5.000e-05, eta: 0:05:12, time: 0.388, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0037, loss_cls: 0.0520, acc: 97.7617, loss_bbox: 0.0895, loss: 0.1475
2022-06-20 18:08:59,757 - mmdet - INFO - Epoch [14][1000/1604]	lr: 5.000e-05, eta: 0:04:48, time: 0.388, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0037, loss_cls: 0.0572, acc: 97.7188, loss_bbox: 0.0869, loss: 0.1496
2022-06-20 18:09:22,949 - mmdet - INFO - Epoch [14][1050/1604]	lr: 5.000e-05, eta: 0:04:24, time: 0.464, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0025, loss_cls: 0.0524, acc: 97.8789, loss_bbox: 0.0773, loss: 0.1341
2022-06-20 18:09:46,908 - mmdet - INFO - Epoch [14][1100/1604]	lr: 5.000e-05, eta: 0:04:00, time: 0.479, data_time: 0.005, memory: 8933, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0033, loss_cls: 0.0575, acc: 97.7812, loss_bbox: 0.0897, loss: 0.1522
2022-06-20 18:10:08,528 - mmdet - INFO - Epoch [14][1150/1604]	lr: 5.000e-05, eta: 0:03:37, time: 0.432, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0025, loss_cls: 0.0454, acc: 98.1250, loss_bbox: 0.0710, loss: 0.1202
2022-06-20 18:10:28,181 - mmdet - INFO - Epoch [14][1200/1604]	lr: 5.000e-05, eta: 0:03:13, time: 0.393, data_time: 0.003, memory: 8933, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0045, loss_cls: 0.0554, acc: 97.7266, loss_bbox: 0.0879, loss: 0.1503
2022-06-20 18:10:52,072 - mmdet - INFO - Epoch [14][1250/1604]	lr: 5.000e-05, eta: 0:02:49, time: 0.478, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0034, loss_cls: 0.0600, acc: 97.5312, loss_bbox: 0.0891, loss: 0.1550
2022-06-20 18:11:11,598 - mmdet - INFO - Epoch [14][1300/1604]	lr: 5.000e-05, eta: 0:02:25, time: 0.391, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0038, loss_cls: 0.0541, acc: 97.6875, loss_bbox: 0.0897, loss: 0.1511
2022-06-20 18:11:30,925 - mmdet - INFO - Epoch [14][1350/1604]	lr: 5.000e-05, eta: 0:02:01, time: 0.387, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0033, loss_cls: 0.0424, acc: 98.1484, loss_bbox: 0.0712, loss: 0.1176
2022-06-20 18:11:56,570 - mmdet - INFO - Epoch [14][1400/1604]	lr: 5.000e-05, eta: 0:01:37, time: 0.513, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0031, loss_cls: 0.0397, acc: 98.3125, loss_bbox: 0.0665, loss: 0.1102
2022-06-20 18:12:16,021 - mmdet - INFO - Epoch [14][1450/1604]	lr: 5.000e-05, eta: 0:01:13, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0036, loss_cls: 0.0566, acc: 97.5586, loss_bbox: 0.0840, loss: 0.1465
2022-06-20 18:12:35,478 - mmdet - INFO - Epoch [14][1500/1604]	lr: 5.000e-05, eta: 0:00:49, time: 0.389, data_time: 0.004, memory: 8933, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0030, loss_cls: 0.0377, acc: 98.5234, loss_bbox: 0.0623, loss: 0.1036
2022-06-20 18:13:02,629 - mmdet - INFO - Epoch [14][1550/1604]	lr: 5.000e-05, eta: 0:00:25, time: 0.543, data_time: 0.006, memory: 8933, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0037, loss_cls: 0.0473, acc: 97.9258, loss_bbox: 0.0823, loss: 0.1354
2022-06-20 18:13:30,146 - mmdet - INFO - Epoch [14][1600/1604]	lr: 5.000e-05, eta: 0:00:01, time: 0.550, data_time: 0.007, memory: 8933, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, loss_cls: 0.0602, acc: 97.5977, loss_bbox: 0.0955, loss: 0.1624
2022-06-20 18:13:31,765 - mmdet - INFO - Saving checkpoint at 14 epochs
2022-06-20 18:15:00,837 - mmdet - INFO - Evaluating bbox...
2022-06-20 18:15:01,581 - mmdet - INFO - 
+-------------+-------+-----------+-------+------------+-------+
| category    | AP    | category  | AP    | category   | AP    |
+-------------+-------+-----------+-------+------------+-------+
| 1_chongkong | 0.559 | 2_hanfeng | 0.472 | 3_yueyawan | 0.626 |
| 4_shuiban   | 0.428 | 5_youban  | 0.233 | 6_siban    | 0.300 |
| 7_yiwu      | 0.150 | 8_yahen   | 0.158 | 9_zhehen   | 0.202 |
| 10_yaozhe   | 0.395 | None      | None  | None       | None  |
+-------------+-------+-----------+-------+------------+-------+
2022-06-20 18:15:01,592 - mmdet - INFO - Exp name: cascade_rcnn_r50_rfp_1x_coco.py
2022-06-20 18:15:01,593 - mmdet - INFO - Epoch(val) [14][688]	bbox_mAP: 0.3520, bbox_mAP_50: 0.7080, bbox_mAP_75: 0.2940, bbox_mAP_s: 0.0840, bbox_mAP_m: 0.2010, bbox_mAP_l: 0.3590, bbox_mAP_copypaste: 0.352 0.708 0.294 0.084 0.201 0.359
